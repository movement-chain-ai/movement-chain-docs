{"config":{"lang":["en"],"separator":"[\\s\\-\\_]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Movement Chain AI Documentation","text":""},{"location":"#system-vision","title":"System Vision","text":"<p>Movement Chain AI is a comprehensive multimodal movement training system designed to provide real-time, intelligent feedback for athletic movements. Initially targeting golf swing analysis and workout form correction, the system combines cutting-edge wearable sensor technology with advanced machine learning to deliver immediate, actionable insights that help users improve their technique and performance.</p>"},{"location":"#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Real-time Movement Analysis: Instant feedback on movement patterns with &lt;100ms latency</li> <li>Multimodal AI Processing: Combines IMU sensor data with video and audio inputs</li> <li>Personalized Training: Adaptive ML models that learn from individual movement patterns</li> <li>Cross-Platform Experience: Seamless mobile app integration on iOS and Android</li> <li>Scalable Architecture: Cloud-native design supporting thousands of concurrent users</li> </ul>"},{"location":"#system-architecture-overview","title":"System Architecture Overview","text":"<p>Movement Chain AI follows a 4-module architecture designed for scalability, maintainability, and performance:</p> <pre><code>graph TB\n    subgraph \"Wearable Device\"\n        A[ESP32-S3 MCU]\n        B[LSM6DSV16X IMU]\n        C[BLE Stack]\n    end\n\n    subgraph \"Mobile Application\"\n        D[Flutter UI]\n        E[BLE Client]\n        F[ONNX Runtime]\n        G[Local Storage]\n    end\n\n    subgraph \"Cloud Backend\"\n        H[API Gateway]\n        I[Lambda Functions]\n        J[DynamoDB]\n        K[S3 Storage]\n        L[SageMaker]\n    end\n\n    subgraph \"ML/AI Module\"\n        M[Training Pipeline]\n        N[Model Registry]\n        O[Feature Engineering]\n    end\n\n    B --&gt;|Motion Data| A\n    A --&gt;|BLE| C\n    C --&gt;|Wireless| E\n    E --&gt; D\n    D --&gt; F\n    F --&gt;|Inference Results| D\n    D --&gt;|Upload| H\n    H --&gt; I\n    I --&gt; J\n    I --&gt; K\n    K --&gt; M\n    M --&gt; N\n    N --&gt;|Model Updates| F\n    L --&gt; M</code></pre>"},{"location":"#module-breakdown","title":"Module Breakdown","text":""},{"location":"#1-wearable-device-module","title":"1. Wearable Device Module","text":"<p>Purpose: Capture high-frequency motion data with minimal latency</p> <ul> <li>MCU: ESP32-S3 (dual-core, BLE 5.0)</li> <li>IMU Sensor: LSM6DSV16X (6-axis, up to 8kHz sampling)</li> <li>Communication: Bluetooth Low Energy 5.0</li> <li>Battery Life: 8+ hours continuous use</li> <li>Form Factor: Wrist-worn device (&lt;50g)</li> </ul> <p>View Hardware Decision Records \u2192</p>"},{"location":"#2-mobile-application-module","title":"2. Mobile Application Module","text":"<p>Purpose: Provide intuitive user interface and edge AI inference</p> <ul> <li>Framework: Flutter (cross-platform iOS/Android)</li> <li>ML Runtime: ONNX Runtime Mobile</li> <li>Features: Real-time visualization, offline mode, workout tracking</li> <li>Inference: On-device ML for &lt;100ms feedback latency</li> <li>Storage: Local SQLite + cloud sync</li> </ul> <p>View Mobile Framework Decision \u2192</p>"},{"location":"#3-cloud-backend-module","title":"3. Cloud Backend Module","text":"<p>Purpose: Scalable data processing and long-term storage</p> <ul> <li>Architecture: AWS Serverless (API Gateway + Lambda + DynamoDB)</li> <li>Storage: S3 for raw sensor data, DynamoDB for metadata</li> <li>API: REST + GraphQL for flexible data access</li> <li>Auth: Cognito for user management</li> <li>Scale: Auto-scaling to handle 10k+ concurrent users</li> </ul> <p>View Integration Patterns \u2192</p>"},{"location":"#4-mlai-module","title":"4. ML/AI Module","text":"<p>Purpose: Train and optimize movement analysis models</p> <ul> <li>Training: AWS SageMaker for distributed training</li> <li>Framework: PyTorch \u2192 ONNX export pipeline</li> <li>Models: Transformer-based sequence models + CNNs</li> <li>Registry: Centralized model versioning and A/B testing</li> <li>Pipeline: Automated retraining on new labeled data</li> </ul> <p>View ONNX Runtime Decision \u2192</p>"},{"location":"#navigation-guide","title":"Navigation Guide","text":""},{"location":"#for-system-architects","title":"For System Architects","text":"<p>Start with the Architecture section to understand the overall system design:</p> <ul> <li>System Overview - Component interactions and responsibilities</li> <li>Data Flow - How data moves through the system</li> <li>Performance Targets - SLAs and scalability goals</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<p>Review the Decisions section to understand key technical choices:</p> <ul> <li>ADR-0004: 4-Module Architecture - Why we chose this structure</li> <li>ADR-0001: Multi-Repo Structure - Code organization strategy</li> <li>ADR-0006: ONNX Runtime - ML deployment approach</li> </ul>"},{"location":"#for-hardware-engineers","title":"For Hardware Engineers","text":"<p>Explore the Resources section for detailed comparisons:</p> <ul> <li>Hardware Comparison - MCU and IMU evaluation</li> <li>Performance Benchmarks - Real-world testing results</li> </ul>"},{"location":"#for-ml-engineers","title":"For ML Engineers","text":"<p>Focus on ML-specific architecture and decisions:</p> <ul> <li>ML/AI Module Design - Training and inference pipeline</li> <li>Model Deployment Strategy - Why ONNX Runtime</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":""},{"location":"#key-architecture-documents","title":"Key Architecture Documents","text":"<ul> <li>System Overview</li> <li>Data Flow Diagrams</li> <li>Integration Patterns</li> </ul>"},{"location":"#critical-design-decisions","title":"Critical Design Decisions","text":"<ul> <li>4-Module Architecture Rationale</li> <li>ESP32-S3 Selection</li> <li>Flutter Mobile Framework</li> </ul>"},{"location":"#technical-comparisons","title":"Technical Comparisons","text":"<ul> <li>MCU Comparison Matrix</li> <li>ML Framework Analysis</li> <li>Mobile Framework Evaluation</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>Documentation Status</p> <p>This documentation is actively maintained and reflects the current system architecture as of December 2025.</p> <p>Current Phase: Architecture Design &amp; Documentation</p> <p>Completed Milestones:</p> <ul> <li> High-level system architecture</li> <li> Hardware component selection</li> <li> Mobile framework evaluation</li> <li> ML deployment strategy</li> <li> Cloud infrastructure design</li> </ul> <p>In Progress:</p> <ul> <li> Detailed API specifications</li> <li> Security and compliance documentation</li> <li> Deployment runbooks</li> <li> Performance benchmarking</li> </ul> <p>Upcoming:</p> <ul> <li> Developer onboarding guides</li> <li> API reference documentation</li> <li> Troubleshooting guides</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions to improve this documentation. See the README for contribution guidelines.</p> <p>Quick contribution checklist:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Test locally with <code>mkdocs serve</code></li> <li>Submit a pull request with clear description</li> </ol>"},{"location":"#support","title":"Support","text":"<p>If you have questions about the architecture or documentation:</p> <ul> <li>Open an issue in the GitHub repository</li> <li>Review existing Architectural Decision Records</li> <li>Check the FAQ section (coming soon)</li> </ul>   **Movement Chain AI** | [GitHub](https://github.com/movement-chain-ai) | [Website](https://movement-chain-ai.com)  *Building the future of intelligent movement training*"}]}