# è¿åŠ¨è®­ç»ƒç³»ç»Ÿçš„å­¦æœ¯ç ”ç©¶ä¸æ•°æ®é›† (Academic Research & Datasets for Movement Training Systems)

> ç»¼åˆæŒ‡å—ï¼Œæ¶µç›–å¯åŠ é€Ÿ Movement Chain AI å¼€å‘çš„å­¦æœ¯ç ”ç©¶ã€æ•°æ®é›†å’Œå·¥å…·

---

## æ¦‚è¿° (Overview)

æœ¬æ–‡æ¡£æ”¶å½•äº†å¥èº«åŠ¨ä½œåˆ†æã€å§¿æ€ä¼°è®¡å’Œåé¦ˆç³»ç»Ÿé¢†åŸŸæœ€é‡è¦çš„å­¦æœ¯ç ”ç©¶å’Œå…¬å¼€å¯ç”¨æ•°æ®é›†ã€‚è¿™äº›èµ„æºå¯ç”¨äºï¼š

- **é¢„è®­ç»ƒ (Pre-training)**: ä½¿ç”¨ç°æœ‰æ•°æ®å¼•å¯¼æ¨¡å‹è®­ç»ƒ
- **åŸºå‡†æµ‹è¯• (Benchmarking)**: å°†æˆ‘ä»¬çš„ç³»ç»Ÿä¸å·²å»ºç«‹çš„åŸºçº¿è¿›è¡Œæ¯”è¾ƒ
- **éªŒè¯ (Validation)**: åœ¨æ ‡å‡†åŒ–æ•°æ®é›†ä¸Šæµ‹è¯•æˆ‘ä»¬çš„æ–¹æ³•
- **ç ”ç©¶ (Research)**: åŸºäºå·²éªŒè¯çš„æ–¹æ³•è®ºè¿›è¡Œæ„å»º

---

## ä¼˜å…ˆçº§ 1ï¼šå¿…ç”¨èµ„æº (Priority 1: Must-Use Resources)

### 1. AIFit - Google/CMU åŸºå‡†ç³»ç»Ÿ (AIFit - Google/CMU Benchmark System)

**è‡ªåŠ¨å¥èº«åé¦ˆç³»ç»Ÿçš„è¡Œä¸šé»„é‡‘æ ‡å‡†ã€‚**

#### å‘è¡¨è¯¦æƒ… (Publication Details)
- **Title**: AIFit: Automatic 3D Human-Interpretable Feedback Models for Fitness Training
- **Authors**: Mihai Fieraru et al. (Google Research / CMU)
- **Venue**: CVPR 2021 (Top-tier Computer Vision Conference)
- **Paper**: [OpenAccess CVPR](https://openaccess.thecvf.com/content/CVPR2021/html/Fieraru_AIFit_Automatic_3D_Human-Interpretable_Feedback_Models_for_Fitness_Training_CVPR_2021_paper.html)
- **Citation**: 100+ citations (highly influential)

#### æ ¸å¿ƒè´¡çŒ® (Core Contributions)

**1. å®Œæ•´åé¦ˆç³»ç»Ÿè®¾è®¡ (Complete Feedback System Design)**
- 3D äººä½“å§¿æ€å’ŒåŠ¨ä½œé‡å»º
- è‡ªåŠ¨é‡å¤åŠ¨ä½œåˆ†å‰²
- ä¸å‚è€ƒåŠ¨ä½œçš„å®æ—¶åå·®æ£€æµ‹
- **è‡ªç„¶è¯­è¨€åé¦ˆç”Ÿæˆ**
- æ—¶ç©ºè§†è§‰æ ‡æ³¨

**2. Fit3D Dataset** (å¯ç”³è¯·è·å–)
- **è§„æ¨¡ (Scale)**: 300 ä¸‡å¼ å›¾åƒåŠå¯¹åº”çš„ 3D åŠ¨ä½œæ•æ‰æ•°æ®
- **è¿åŠ¨é¡¹ç›® (Exercises)**: 37+ ç§é‡å¤æ€§å¥èº«åŠ¨ä½œ
- **è¦†ç›–èŒƒå›´ (Coverage)**: æ‰€æœ‰ä¸»è¦è‚Œè‚‰ç¾¤
- **å‚ä¸è€… (Participants)**: åŒ…æ‹¬ä¸“ä¸šæ•™ç»ƒå’Œå­¦ä¹ è€…
- **è´¨é‡ (Quality)**: ä¸“ä¸šåŠ¨ä½œæ•æ‰ç³»ç»Ÿ
- **Website**: [https://fit3d.imar.ro/](https://fit3d.imar.ro/)

**3. å¯è°ƒèŠ‚åé¦ˆä¸¥æ ¼åº¦ (Adjustable Feedback Strictness)**
- æ§åˆ¶åé¦ˆä¸¥æ ¼ç¨‹åº¦çš„å…¨å±€å‚æ•°
- é€‚åº”åˆå­¦è€… â†’ ä¸­çº§ â†’ é«˜çº§ç”¨æˆ·
- è€ƒè™‘å§¿æ€ä¼°è®¡çš„ä¸ç¡®å®šæ€§

#### Movement Chain AI å¦‚ä½•ä½¿ç”¨ (How Movement Chain AI Can Use This)

âœ… **ç”³è¯· Fit3D æ•°æ®é›†è®¿é—®æƒé™** - ç”¨äºï¼š
- é¢„è®­ç»ƒå§¿æ€ä¼°è®¡æ¨¡å‹
- å¯¹æˆ‘ä»¬çš„åé¦ˆç³»ç»Ÿè¿›è¡ŒåŸºå‡†æµ‹è¯•
- æ¯”è¾ƒè‡ªç„¶è¯­è¨€ç”Ÿæˆæ•ˆæœ

âœ… **é‡‡ç”¨åé¦ˆç³»ç»Ÿè®¾è®¡æ¨¡å¼**ï¼š
- å¤šå±‚çº§åé¦ˆï¼ˆè§†è§‰ + è¯­è¨€ï¼‰
- ç½®ä¿¡åº¦æ„ŸçŸ¥çš„åé¦ˆä¼ é€’
- æŠ€èƒ½è‡ªé€‚åº”ä¸¥æ ¼åº¦

âœ… **å‚è€ƒè¯„ä¼°æŒ‡æ ‡**ï¼š
- ä½¿ç”¨ä»–ä»¬çš„è¯„ä¼°æ¡†æ¶è¿›è¡Œæˆ‘ä»¬è‡ªå·±çš„è¯„ä¼°

#### èµ„æº (Resources)
- **Code & Tools**: [GitHub - Dataset Tools](https://github.com/sminchisescu-research/imar_vision_datasets_tools)
- **Dataset Access**: [Apply at fit3d.imar.ro](https://fit3d.imar.ro/)
- **Documentation**: åŒ…å«æ•°æ®é›†ç»“æ„çš„å®Œæ•´ README

---

### 2. MM-Fit - å¤šæ¨¡æ€å¥èº«æ•°æ®é›† (MM-Fit - Multimodal Fitness Dataset)

**ä¸æˆ‘ä»¬é¡¹ç›®æœ€åŒ¹é… - ç»“åˆäº†å¯ç©¿æˆ´è®¾å¤‡ + è§†è§‰ï¼**

#### å‘è¡¨è¯¦æƒ… (Publication Details)
- **Title**: MM-Fit: Multimodal Deep Learning for Automatic Exercise Logging across Sensing Devices
- **Authors**: Stromback et al.
- **Venue**: IMWUT 2020 (Top Ubicomp Journal)
- **Website**: [https://mmfit.github.io/](https://mmfit.github.io/)
- **GitHub**: [https://github.com/KDMStromback/mm-fit](https://github.com/KDMStromback/mm-fit)

#### æ•°æ®é›†å†…å®¹ (Dataset Contents)

**ä¼ æ„Ÿå™¨æ•°æ® (Sensor Data)** (æ—¶é—´åŒæ­¥ï¼)
- Smartphone IMU (accelerometer + gyroscope)
- Smartwatch IMU
- Earbuds IMU
- Multi-view RGB-D video
- 2D pose estimation landmarks
- 3D pose reconstruction

**è¿åŠ¨è¦†ç›– (Exercise Coverage)**
- å„ç§å¥èº«æˆ¿è¿åŠ¨
- å¤šåå‚ä¸è€…
- è‡ªç„¶ç¯å¢ƒæ•æ‰

#### ä¸ºä»€ä¹ˆè¿™å¯¹ Movement Chain AI é‡è¦ (Why This Matters for Movement Chain AI)

ğŸ¯ **å®Œç¾çš„éªŒè¯æ•°æ®é›†** - æ­£å¥½æ‹¥æœ‰æˆ‘ä»¬éœ€è¦çš„ï¼š
- IMU æ•°æ®ï¼ˆç±»ä¼¼æˆ‘ä»¬çš„å¯ç©¿æˆ´è®¾å¤‡ï¼‰
- è§†é¢‘æ•°æ®ï¼ˆç±»ä¼¼æˆ‘ä»¬çš„ç§»åŠ¨åº”ç”¨ï¼‰
- çœŸå®å§¿æ€æ ‡æ³¨ï¼ˆç”¨äºè¯„ä¼°ï¼‰
- **å…¨éƒ¨æ—¶é—´åŒæ­¥** - è§£å†³åŒæ­¥æŒ‘æˆ˜

âœ… **ç›´æ¥åº”ç”¨ (Direct applications)**ï¼š
1. éªŒè¯æˆ‘ä»¬çš„ä¼ æ„Ÿå™¨èåˆæ–¹æ³•ï¼ˆIMU + Visionï¼‰
2. æµ‹è¯•æˆ‘ä»¬çš„å§¿æ€ä¼°è®¡ç®¡é“
3. å¯¹å¤šæ¨¡æ€å­¦ä¹ è¿›è¡ŒåŸºå‡†æµ‹è¯•
4. å‚è€ƒä»–ä»¬çš„æ—¶é—´åŒæ­¥æ–¹æ³•

#### ä¸‹è½½ä¸ä½¿ç”¨ (Download & Usage)
- **Access**: å…¬å¼€å¯ç”¨ï¼ˆæŸ¥çœ‹ GitHub è·å–é“¾æ¥ï¼‰
- **Format**: æ ‡å‡†æ ¼å¼ï¼ˆHDF5ã€CSV ç”¨äºä¼ æ„Ÿå™¨ï¼›è§†é¢‘æ–‡ä»¶ï¼‰
- **License**: å…è®¸å­¦æœ¯ä½¿ç”¨ï¼ˆéªŒè¯å½“å‰æ¡æ¬¾ï¼‰

---

### 3. FLAG3D - è¯­è¨€å¼•å¯¼çš„ 3D å¥èº«æ•°æ®é›† (FLAG3D - Language-Guided 3D Fitness Dataset)

**æœ€æ–°çš„å¸¦è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„å¤§è§„æ¨¡å¥èº«æ•°æ®é›†ã€‚**

#### å‘è¡¨è¯¦æƒ… (Publication Details)
- **Title**: FLAG3D: A 3D Fitness Activity Dataset with Language Instruction
- **Venue**: CVPR 2023
- **Paper**: [arXiv:2212.04638](https://arxiv.org/abs/2212.04638)
- **Project Page**: [https://andytang15.github.io/FLAG3D/](https://andytang15.github.io/FLAG3D/)

#### æ•°æ®é›†ç‰¹æ€§ (Dataset Characteristics)

**è§„æ¨¡ (Scale)**
- **180,000** ä¸ªåŠ¨ä½œåºåˆ—
- **60** ç§å¤æ‚å¥èº«åŠ¨ä½œ
- å¤šç§æ•æ‰æ¨¡å¼

**æ•°æ®æ¥æº (Data Sources)**
1. **ä¸“ä¸šåŠ¨æ• (Professional MoCap)**ï¼š
   - 24 å° VICON æ‘„åƒæœº
   - 77 ä¸ªæ ‡è®°ç‚¹
   - ç ”ç©¶çº§ç²¾åº¦

2. **åˆæˆæ¸²æŸ“ (Synthetic Rendering)**ï¼š
   - è½¯ä»¶ç”Ÿæˆçš„å˜ä½“
   - å—æ§æ¡ä»¶

3. **æ™ºèƒ½æ‰‹æœºè‡ªç„¶æ•æ‰ (Smartphone Natural)**ï¼š
   - çœŸå®ä¸–ç•Œç¯å¢ƒ
   - æ¶ˆè´¹çº§æ•æ‰
   - åŒ¹é…éƒ¨ç½²æ¡ä»¶

**ç‹¬ç‰¹åŠŸèƒ½ (Unique Feature)**: è¯¦ç»†çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ ‡æ³¨

#### å¯¹ Movement Chain AI çš„ä»·å€¼ (Value for Movement Chain AI)

âœ… **è‡ªç„¶è¯­è¨€åé¦ˆè®¾è®¡**ï¼š
- å‚è€ƒä»–ä»¬çš„æŒ‡ä»¤æ ¼å¼
- å­¦ä¹ è¯­è¨€åˆ°å§¿æ€çš„æ˜ å°„
- è®­ç»ƒ/æµ‹è¯•è¯­è¨€ç”Ÿæˆæ¨¡å‹

âœ… **å¤šæ ·åŒ–æ•°æ®æº**ï¼š
- ä¸“ä¸šåŠ¨æ•ä½œä¸ºçœŸå®æ ‡æ³¨
- æ™ºèƒ½æ‰‹æœºæ•°æ®åŒ¹é…æˆ‘ä»¬çš„ä½¿ç”¨åœºæ™¯
- åˆæˆæ•°æ®ç”¨äºæ•°æ®å¢å¼º

---

### 4. Microsoft RecoFit æ•°æ®é›† (Microsoft RecoFit Dataset)

**ä¸“æ³¨äºåŸºäºå¯ç©¿æˆ´ä¼ æ„Ÿå™¨çš„è¿åŠ¨è¯†åˆ«ã€‚**

#### å‘è¡¨è¯¦æƒ… (Publication Details)
- **Paper**: RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises (CHI 2014)
- **Authors**: Morris, D., Saponas, T. S., Guillory, A., & Kelner, I.
- **GitHub**: [https://github.com/microsoft/Exercise-Recognition-from-Wearable-Sensors](https://github.com/microsoft/Exercise-Recognition-from-Wearable-Sensors)

#### æ•°æ®é›†å†…å®¹ (Dataset Contents)
- **200+ åå‚ä¸è€… (participants)**
- Accelerometer + Gyroscope æ•°æ®
- å¥èº«æˆ¿è¿åŠ¨å½•åˆ¶
- é‡å¤æ¬¡æ•°æ ‡ç­¾

#### ä½¿ç”¨åœºæ™¯ (Use Cases)
- ä»… IMU çš„è¿åŠ¨è¯†åˆ«åŸºçº¿
- ä¸ºæˆ‘ä»¬çš„å¯ç©¿æˆ´è®¾å¤‡æ¨¡å—è¿›è¡Œé¢„è®­ç»ƒ
- é‡å¤æ¬¡æ•°è®¡ç®—ç®—æ³•éªŒè¯

---

## ä¼˜å…ˆçº§ 2ï¼šæ”¯æŒæ€§ç ”ç©¶ (Priority 2: Supporting Research)

### UCSD-MIT Human Motion Capture Dataset
- **Link**: [http://humanmotion.ict.usc.edu/](http://humanmotion.ict.usc.edu/)
- **Content**: å„ç§æ´»åŠ¨çš„ä¸“ä¸šåŠ¨ä½œæ•æ‰
- **Use**: åŸºçº¿è¿åŠ¨æ¨¡å¼

### COCO Keypoint Dataset
- **Link**: [https://cocodataset.org/#keypoints-2020](https://cocodataset.org/#keypoints-2020)
- **Content**: 20 ä¸‡å¼ å¸¦å§¿æ€å…³é”®ç‚¹çš„å›¾åƒ
- **Use**: é¢„è®­ç»ƒå§¿æ€ä¼°è®¡æ¨¡å‹

### MPII Human Pose Dataset
- **Link**: [http://human-pose.mpi-inf.mpg.de/](http://human-pose.mpi-inf.mpg.de/)
- **Content**: 25K å¼ å›¾åƒï¼Œ40K+ äººç‰©ï¼Œ410 ç§æ´»åŠ¨
- **Use**: å§¿æ€ä¼°è®¡è®­ç»ƒ/è¯„ä¼°

---

## æ¨èçš„æ•°æ®é›†ä½¿ç”¨ç­–ç•¥ (Recommended Dataset Usage Strategy)

### é˜¶æ®µ 1ï¼šMVP å¼€å‘ï¼ˆå½“å‰ï¼‰(Phase 1: MVP Development (Current))
**é‡ç‚¹ (Focus)**: å¿«é€Ÿè·å¾—å¯å·¥ä½œçš„åŸå‹

| æ•°æ®é›† Dataset | ç›®çš„ Purpose | ä¼˜å…ˆçº§ Priority |
|---------|---------|----------|
| **MM-Fit** | éªŒè¯ä¼ æ„Ÿå™¨èåˆ | ğŸ”´ Critical |
| **COCO Keypoints** | é¢„è®­ç»ƒå§¿æ€æ¨¡å‹ | ğŸŸ¡ High |
| **RecoFit** | IMU åŸºçº¿ | ğŸŸ¢ Medium |

### é˜¶æ®µ 2ï¼šç³»ç»Ÿä¼˜åŒ– (Phase 2: System Refinement)
**é‡ç‚¹ (Focus)**: æé«˜å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›

| æ•°æ®é›† Dataset | ç›®çš„ Purpose | ä¼˜å…ˆçº§ Priority |
|---------|---------|----------|
| **Fit3D** (å¦‚è·å¾—è®¿é—®æƒé™) | å¯¹åé¦ˆç³»ç»Ÿè¿›è¡ŒåŸºå‡†æµ‹è¯• | ğŸ”´ Critical |
| **FLAG3D** | è¯­è¨€åé¦ˆè®¾è®¡ | ğŸŸ¡ High |
| **MPII** | å§¿æ€ä¼°è®¡é²æ£’æ€§ | ğŸŸ¢ Medium |

### é˜¶æ®µ 3ï¼šç ”ç©¶å‘è¡¨ (Phase 3: Research Publication)
**é‡ç‚¹ (Focus)**: æ–°é¢–è´¡çŒ®å’Œæ¯”è¾ƒ

| æ•°æ®é›† Dataset | ç›®çš„ Purpose | ä¼˜å…ˆçº§ Priority |
|---------|---------|----------|
| **Fit3D** | ä¸ AIFit åŸºçº¿æ¯”è¾ƒ | ğŸ”´ Critical |
| **MM-Fit** | å¤šæ¨¡æ€èåˆæ¯”è¾ƒ | ğŸ”´ Critical |
| **Custom Dataset** | EMG + Hapticï¼ˆæˆ‘ä»¬çš„ç‹¬ç‰¹æ•°æ®ï¼‰ | ğŸ”´ Critical |

---

## æ•°æ®é›†ç”³è¯·æµç¨‹ (Dataset Application Process)

### Fit3D æ•°æ®é›†è®¿é—® (Fit3D Dataset Access)

**æ­¥éª¤ (Steps)**ï¼š
1. è®¿é—® [https://fit3d.imar.ro/](https://fit3d.imar.ro/)
2. å®Œæˆå­¦æœ¯/ç ”ç©¶ç”³è¯·è¡¨
3. æŒ‡å®šä½¿ç”¨åœºæ™¯ï¼š"Multimodal movement training with EMG and haptic feedback"
4. ç­‰å¾…æ‰¹å‡†ï¼ˆé€šå¸¸ 1-2 å‘¨ï¼‰
5. ç­¾ç½²æ•°æ®ä½¿ç”¨åè®®

**è¦å¼ºè°ƒçš„å†…å®¹ (What to Highlight)**ï¼š
- å­¦æœ¯ç ”ç©¶é¡¹ç›®
- æ–°é¢–çš„å¤šæ¨¡æ€æ–¹æ³•ï¼ˆEMG + IMU + Visionï¼‰
- å¼€æºè´¡çŒ®ç›®æ ‡
- ä¸ AIFit æ–¹æ³•è®ºçš„æ¯”è¾ƒ

---

## é›†æˆè·¯çº¿å›¾ (Integration Roadmap)

### å³æ—¶è¡ŒåŠ¨ï¼ˆç¬¬ 1-2 å‘¨ï¼‰(Immediate Actions (Week 1-2))
- [ ] ä¸‹è½½ MM-Fit æ•°æ®é›†
- [ ] ä¸‹è½½ RecoFit æ•°æ®é›†
- [ ] ä¸‹è½½ COCO Keypoints é¢„è®­ç»ƒæ¨¡å‹
- [ ] ç”³è¯· Fit3D è®¿é—®æƒé™

### çŸ­æœŸï¼ˆç¬¬ 1 ä¸ªæœˆï¼‰(Short-term (Month 1))
- [ ] åœ¨ COCO ä¸ŠéªŒè¯å§¿æ€ä¼°è®¡
- [ ] åœ¨ RecoFit ä¸Šæµ‹è¯• IMU å¤„ç†
- [ ] åœ¨ MM-Fit ä¸Šå¯¹ä¼ æ„Ÿå™¨èåˆè¿›è¡ŒåŸºå‡†æµ‹è¯•
- [ ] åŸºäº AIFit è®¾è®¡è¯„ä¼°æŒ‡æ ‡

### ä¸­æœŸï¼ˆç¬¬ 2-3 ä¸ªæœˆï¼‰(Medium-term (Month 2-3))
- [ ] å¦‚æœè·å¾— Fit3D è®¿é—®æƒé™ï¼Œå¯¹å®Œæ•´ç³»ç»Ÿè¿›è¡ŒåŸºå‡†æµ‹è¯•
- [ ] å°†è¯­è¨€åé¦ˆä¸ FLAG3D æ¯”è¾ƒ
- [ ] åœ¨ MM-Fit ä¸Šå‘å¸ƒåˆæ­¥ç»“æœ
- [ ] æ”¶é›†æˆ‘ä»¬è‡ªå·±çš„å¸¦ EMG çš„æ•°æ®é›†

---

## å¼•ç”¨è¦æ±‚ (Citation Requirements)

åœ¨å‡ºç‰ˆç‰©æˆ–æ–‡æ¡£ä¸­ä½¿ç”¨è¿™äº›æ•°æ®é›†æ—¶ï¼š

**AIFit / Fit3D**:
```
@inproceedings{fieraru2021aifit,
  title={AIFit: Automatic 3D Human-Interpretable Feedback Models for Fitness Training},
  author={Fieraru, Mihai and others},
  booktitle={CVPR},
  year={2021}
}
```

**MM-Fit**:
```
@article{stromback2020mmfit,
  title={MM-Fit: Multimodal Deep Learning for Automatic Exercise Logging across Sensing Devices},
  author={Stromback, KDM and others},
  journal={IMWUT},
  year={2020}
}
```

**FLAG3D**:
```
@inproceedings{tang2023flag3d,
  title={FLAG3D: A 3D Fitness Activity Dataset with Language Instruction},
  booktitle={CVPR},
  year={2023}
}
```

---

## ç›¸å…³ç ”ç©¶è®ºæ–‡ (Related Research Papers)

### å§¿æ€ä¼°è®¡ (Pose Estimation)
- **OpenPose**: Realtime Multi-Person 2D Pose Estimation (CVPR 2017)
- **MediaPipe**: BlazePose - On-device Real-time Body Pose Tracking (CVPR Workshop 2020)
- **RTMPose**: Pushing the Limit of Real-time Multi-person Pose Estimation (arXiv 2023)

### è¿åŠ¨è¯†åˆ« (Exercise Recognition)
- **RepNet**: Counting Out Time - Class Agnostic Video Repetition Counting (CVPR 2020)
- **TransRAC**: Transformer-based Repetitive Action Counting (ICCV 2021)

### åé¦ˆç³»ç»Ÿ (Feedback Systems)
- **AIFit**: Automatic 3D Human-Interpretable Feedback (CVPR 2021)
- **SkillAR**: AR-based Motor Skill Learning with Visual Feedback (CHI 2022)

---

## æ€»ç»“è¡¨ (Summary Table)

| èµ„æº Resource | ç±»å‹ Type | è§„æ¨¡ Scale | è®¿é—® Access | æœ€é€‚åˆ Best For |
|----------|------|-------|--------|----------|
| **Fit3D** | MoCap + Images | 3M images, 37 exercises | Application required | Benchmark gold standard |
| **MM-Fit** | Multimodal | Various exercises | Public | Sensor fusion validation |
| **FLAG3D** | 3D + Language | 180K sequences, 60 exercises | Public | Language feedback design |
| **RecoFit** | IMU Only | 200+ participants | Public | Wearable baseline |
| **COCO** | 2D Keypoints | 200K+ images | Public | Pose pre-training |
| **MPII** | 2D Keypoints | 25K images | Public | Pose evaluation |

---

**Last Updated**: December 2025
**Maintainer**: Movement Chain AI Research Team
**Next Review**: Q1 2026
