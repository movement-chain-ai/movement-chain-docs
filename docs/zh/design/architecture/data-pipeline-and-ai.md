# 数据流与反馈架构

> **文档状态**: 草稿 v1.2
> **最后更新**: 2025-12-23
> **关联文档**: [模块化架构](modular-architecture.md) | [实时反馈](../specs/real-time-feedback.md) | [生物力学基准](../../prerequisites/foundations/biomechanics-benchmarks.md) | [关键决策 2025-12](../decisions/architecture-decisions-2025-12-23.md)

---

## 引言

### 文档目的

本文档回答 Movement Chain AI 系统的四个核心问题，帮助团队成员理解数据如何从传感器流向用户反馈。

### 核心问题导读

| 问题 | 简短回答 | 详细章节 |
|-----|---------|---------|
| 每个时间戳有什么数据? | 原始传感器数据 + 计算特征，两者都有 | [§1 时间对齐数据结构](#1-时间对齐数据结构) |
| 数据如何变成用户反馈? | 特征提取 → Kinematic Prompt → LLM 反馈 (挥杆后) | [§2 反馈生成架构](#2-反馈生成架构) |
| "标准"从哪里来? | TPI + 学术论文，基于研究不是猜测 | [§3 标准与阈值来源](#3-标准与阈值来源) |
| 用户实际看到什么? | 简单界面 + 语音反馈，不是复杂图表 | [§4 用户体验设计](#4-用户体验设计) |

### 阅读建议

- **快速了解**: 阅读每节的第一个小节 (1.1, 2.1, 3.1, 4.1)
- **深入理解**: 按顺序阅读全文
- **开发参考**: 关注代码示例和数据格式定义

---

## 1. 时间对齐数据结构 {#1-时间对齐数据结构}

### 1.1 数据全景图

在任意时间戳 (例如 t=100ms)，系统同时拥有两类数据：

```text
┌────────────────────────────────────────────────────────────────┐
│              t=100ms 时刻的完整数据                             │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  ┌─ 原始传感器数据 (RAW DATA) ─────────────────────────────┐   │
│  │                                                         │   │
│  │  MediaPipe Vision:                                      │   │
│  │    33 个关键点 × (x, y, z, visibility)                  │   │
│  │    例: landmarks[11] = {x: 0.45, y: 0.32, z: -0.1, v: 0.98} │
│  │                                                         │   │
│  │  IMU (1666Hz):                                          │   │
│  │    gyro:  {x: 12.3, y: -5.1, z: -450.2} °/s             │   │
│  │    accel: {x: 0.2, y: 9.7, z: 0.5} m/s²                 │   │
│  │                                                         │   │
│  │  EMG (1000Hz):                                          │   │
│  │    core_mV: 0.45 mV                                     │   │
│  │    forearm_mV: 0.12 mV                                  │   │
│  │                                                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                │
│  ┌─ 计算特征 (COMPUTED FEATURES) ──────────────────────────┐   │
│  │                                                         │   │
│  │  Vision 指标:                                           │   │
│  │    x_factor: 42.3°    (肩髋分离角)                      │   │
│  │    s_factor: 35.1°    (肩部倾斜)                        │   │
│  │    o_factor: 8.2°     (骨盆倾斜)                        │   │
│  │                                                         │   │
│  │  IMU 指标:                                              │   │
│  │    peak_velocity: 850°/s   (当前角速度)                 │   │
│  │    phase_hint: "BACKSWING" (推测阶段)                   │   │
│  │                                                         │   │
│  │  EMG 指标:                                              │   │
│  │    core_activation: 45%    (核心激活程度)               │   │
│  │    forearm_activation: 12% (前臂激活程度)               │   │
│  │                                                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                                                                │
│  ✅ 两类数据在同一时间戳同时存在                               │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

**关键点**: 就像竞品 Form/Sportsbox 一样，我们在每帧都计算 X-Factor 等指标，而不是只在挥杆结束后计算。

---

### 1.2 原始传感器数据

#### MediaPipe Vision (30fps)

```python
# 每帧输出 33 个关键点
PoseLandmark = {
    "x": float,        # 归一化坐标 [0, 1]
    "y": float,        # 归一化坐标 [0, 1]
    "z": float,        # 深度 (相对值)
    "visibility": float # 可见度 [0, 1]
}

# 关键关键点索引
LANDMARKS = {
    11: "left_shoulder",
    12: "right_shoulder",
    23: "left_hip",
    24: "right_hip",
    # ... 共 33 个
}
```

#### IMU (1666Hz, 最高支持 7.68kHz)

```python
@dataclass
class IMUFrame:
    timestamp_us: int      # 微秒时间戳 - 来自 ESP32 esp_timer_get_time()
    gyro_x: float          # 角速度 X (°/s)
    gyro_y: float          # 角速度 Y (°/s)
    gyro_z: float          # 角速度 Z (°/s) ← 主要旋转轴
    accel_x: float         # 加速度 X (m/s²)
    accel_y: float         # 加速度 Y (m/s²)
    accel_z: float         # 加速度 Z (m/s²)
```

#### EMG (1000Hz)

```python
@dataclass
class EMGFrame:
    timestamp_us: int      # 微秒时间戳 - 来自 ESP32 esp_timer_get_time()
    core_mV: float         # 核心肌群电压 (mV)
    forearm_mV: float      # 前臂肌群电压 (mV)
```

#### 时间同步策略

!!! warning "BLE 时间抖动 - 关键风险 (2025-12 验证)"
    **❌ 错误方法**: 使用 iPhone 接收时间作为传感器时间戳

    - BLE 连接间隔抖动: ±15-30ms (随机)
    - 这个抖动会掩盖真实的 20-50ms 肌肉激活差异
    - Downswing 阶段仅 200-400ms,30ms 误差 = 7.5-15% 相位错误

    **✅ 正确方法**: ESP32 源端时间戳 + Sensor Hub 架构

    - 同一身体部位的 IMU + EMG 共享同一个 ESP32 时钟
    - 使用 `esp_timer_get_time()` 在采集时立即打微秒时间戳
    - 跨设备使用 Impact 事件对齐

    详见 [关键决策 2025-12](../decisions/architecture-decisions-2025-12-23.md#45-视频与传感器同步方案)

```text
IMU 是主时钟 (Master Clock):
├── Vision 30fps → 线性插值到 1666Hz
├── EMG 1000Hz  → 三次样条插值到 1666Hz
└── IMU 1666Hz  → 参考轴 (不变)

同步要求: 误差 < 10ms
```

!!! tip "实现细节"
    时间同步的具体实现方案（NTP 预同步 + Impact 验证）详见
    [模块化架构 §2.4.1](modular-architecture.md#241-时间同步实现方案)。

#### Sensor Hub 架构 (2025-12 推荐)

```text
┌─────────────────────────────────────────────────────────────────┐
│                    Sensor Hub 时间同步架构                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   层级 1: Sensor Hub 内部同步 (同一 ESP32)                       │
│   ───────────────────────────────────                       │
│   ESP32 #1 (手臂):          ESP32 #2 (核心):                    │
│     ├── IMU (I2C)              ├── IMU (I2C)                   │
│     └── EMG (ADC)              └── EMG (ADC)                   │
│   esp_timer_get_time()       esp_timer_get_time()              │
│   精度: <10 μs               精度: <10 μs                       │
│                                                                 │
│   层级 2: 跨 Sensor Hub 对齐 (Impact 事件)                       │
│   ───────────────────────────────────────                       │
│   1. 各 Sensor Hub 独立记录(带 ESP32 源时间戳)                   │
│   2. 挥杆后,使用 Impact 时刻作为 T=0 对齐                        │
│   精度: 69-477 μs (取决于 IMU ODR)                              │
│                                                                 │
│   层级 3: Vision 对齐                                           │
│   ───────────────────────────────────────                       │
│   Vision 30fps → 使用 Impact 帧对齐到传感器 T=0                  │
│   精度: ±16.7ms (30fps 帧间隔)                                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**同步精度总结**:

| 场景 | 目标精度 | 实际可达 | 方法 |
|------|---------|---------|------|
| 同一 ESP32 (IMU+EMG) | <100 μs | <10 μs | esp_timer_get_time() |
| 跨 ESP32 (手臂↔核心) | <1 ms | 69-477 μs | Impact 对齐 |
| 跨设备 (ESP32↔Vision) | <10 ms | <5 ms | Impact 帧对齐 |

---

### 1.3 计算特征

#### Vision 指标 (从 MediaPipe 计算)

| 指标 | 公式 | 单位 | 正常范围 |
|-----|------|-----|---------|
| **X-Factor** | `abs(shoulder_angle) - abs(hip_angle)` | 度 (°) | 35-55° |
| **S-Factor** | `atan2(shoulder_height_diff, shoulder_width)` | 度 (°) | 30-40° |
| **O-Factor** | `atan2(hip_height_diff, hip_width)` | 度 (°) | 5-10° |
| **Sway** | `hip_center.x - address_hip_center.x` | 归一化 | < 0.03 |
| **Lift** | `hip_center.y - address_hip_center.y` | 归一化 | < 0.02 |

**X-Factor 计算示例**:

```python
def calculate_x_factor(landmarks):
    # 肩膀旋转角度
    shoulder_angle = math.atan2(
        landmarks[12].z - landmarks[11].z,  # 深度差
        landmarks[12].x - landmarks[11].x   # 水平差
    )

    # 骨盆旋转角度
    hip_angle = math.atan2(
        landmarks[24].z - landmarks[23].z,
        landmarks[24].x - landmarks[23].x
    )

    # X-Factor = 肩髋分离角
    return math.degrees(abs(shoulder_angle) - abs(hip_angle))
```

#### IMU 指标

| 指标 | 计算方法 | 单位 | 正常范围 |
|-----|---------|-----|---------|
| **Peak Velocity** | `max(abs(gyro_z))` | °/s | > 800°/s |
| **Tempo Ratio** | `backswing_time / downswing_time` | 比值 | 2.5-3.5 |
| **Top 检测** | `gyro_z` 零交叉点 (负→正) | ms | ±9-15ms 精度 |
| **Impact 检测** | `gyro_z` 峰值点 | ms | ±9-15ms 精度 |

#### EMG 指标

| 指标 | 计算方法 | 单位 | 正常范围 |
|-----|---------|-----|---------|
| **Core Activation** | `RMS(core_mV) / MVC_baseline` | % | > 50% |
| **Forearm Activation** | `RMS(forearm_mV) / MVC_baseline` | % | 40-60% |
| **Core Onset Time** | 信号首次超过阈值的时刻 | ms | - |
| **Forearm Onset Time** | 信号首次超过阈值的时刻 | ms | - |
| **Timing Gap** | `forearm_onset - core_onset` | ms | > 20ms (核心先) |

---

### 1.4 Rerun 开发者可视化

Rerun 是**开发者调试工具**，用于验证多流数据是否正确对齐。

```text
┌────────────────────────────────────────────────────────────────┐
│              Rerun 时间轴可视化 (开发者视角)                    │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  时间轴 (ms):  0    200   400   600   800   1000  1200        │
│  ─────────────────────────────────────────────────────────────│
│                                                                │
│  📷 Video:     ●────●────●────●────●────●────●────●           │
│                     (每 33ms 一帧)                             │
│                                                                │
│  🔄 gyro_z:    ─────────────────●─────────●─────────          │
│                              (Top)     (Impact)                │
│                           零交叉点     峰值点                  │
│                                                                │
│  💪 Core EMG:  ─────────────────●──────────────────           │
│                              (激活)                            │
│                              485ms                             │
│                                                                │
│  💪 Forearm:   ───────────────────────●────────────           │
│                                     (激活)                     │
│                                     540ms                      │
│                                                                │
│  ─────────────────────────────────────────────────────────────│
│                                                                │
│  验证点:                                                       │
│  ✅ Top (零交叉) 对齐 Video 帧中手臂最高点                     │
│  ✅ Impact (峰值) 对齐 Video 帧中击球瞬间                      │
│  ✅ Core EMG 在 Top 之前激活 (485ms < Top)                     │
│  ✅ Core 在 Forearm 之前激活 (485ms < 540ms = +55ms gap)       │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

!!! warning "重要区分"
    Rerun 是**开发者工具**，用于调试和验证。
    用户的手机 App 不会显示这些复杂图表。
    用户体验设计见 [§4 用户体验设计](#4-用户体验设计)。

---

## 2. 反馈生成架构 {#2-反馈生成架构}

### 2.1 端到端数据流

```text
┌────────────────────────────────────────────────────────────────┐
│                    端到端数据流                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  ┌─────────┐   ┌─────────┐   ┌─────────┐                      │
│  │ 📷 摄像头│   │ 🔄 IMU  │   │ 💪 EMG  │                      │
│  └────┬────┘   └────┬────┘   └────┬────┘                      │
│       │             │             │                            │
│       ▼             ▼             ▼                            │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │              特征提取层 (Feature Extraction)             │  │
│  │  MediaPipe → 33点   IMU → 6轴    EMG → 2通道            │  │
│  │  计算: X-Factor等   计算: 相位    计算: 激活%           │  │
│  └─────────────────────────────────────────────────────────┘  │
│                            │                                   │
│                            ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │              判断层 (Decision Layer)                     │  │
│  │                                                          │  │
│  │  ┌─────────────────┐    ┌─────────────────┐             │  │
│  │  │   规则引擎      │ 或 │    AI 分析      │             │  │
│  │  │  (硬编码规则)   │    │  (LLM/模型)     │             │  │
│  │  └─────────────────┘    └─────────────────┘             │  │
│  │                                                          │  │
│  │  输出: 触发的规则列表 + 严重程度 (P0/P1/P2)              │  │
│  └─────────────────────────────────────────────────────────┘  │
│                            │                                   │
│                            ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │              翻译层 (Translation Layer)                  │  │
│  │                                                          │  │
│  │  输入: "ARMS_BEFORE_CORE 触发, gap=-25ms"               │  │
│  │  LLM: "你的手臂比身体先动了，让身体带动手臂"            │  │
│  │                                                          │  │
│  └─────────────────────────────────────────────────────────┘  │
│                            │                                   │
│                            ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐  │
│  │              输出层 (Output Layer)                       │  │
│  │                                                          │  │
│  │  🔊 语音: "从核心启动"                                   │  │
│  │  📱 屏幕: 简单文字 + 分数                                │  │
│  │  📳 震动: (可选)                                         │  │
│  │                                                          │  │
│  └─────────────────────────────────────────────────────────┘  │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

### 2.2 三种架构方案对比

#### 方案 A: 规则 + LLM 翻译 (保守)

```text
特征 ──→ 硬编码规则引擎 ──→ 触发的规则 ──→ LLM翻译 ──→ 用户反馈
              │
              │  IF timing_gap < -20ms:
              │      return "ARMS_BEFORE_CORE"
              │
              │  IF x_factor >= 35 AND core_activation < 50%:
              │      return "FALSE_COIL"
```

| 优点 | 缺点 |
|-----|-----|
| ✅ 100% 可预测 | ❌ 不够灵活 |
| ✅ 不会幻觉/编造 | ❌ 无法处理规则外情况 |
| ✅ 低延迟 (规则执行 <5ms) | ❌ 无法个性化 |
| ✅ 成本低 (LLM只做翻译) | ❌ 需要人工维护规则 |

#### 方案 B: Kinematic Prompts + LLM 推理 (研究验证)

> **研究来源**: BoxingPro (2025), SportsGPT (2025) 验证了此架构

```text
计算特征 ──→ Kinematic Prompt 生成 ──→ LLM 推理 ──→ 个性化反馈
              │
              │  将结构化特征转换为 LLM 可理解的文本:
              │  "X-Factor=42° (✅ 在 35-55° 范围内)
              │   Core=45% (⚠️ 低于 50% 阈值)
              │   Timing Gap=+55ms (✅ 核心先于前臂)"
              │
              │  LLM 基于上下文推理，生成教练级反馈
```

**关键洞察**: LLM 不擅长处理原始传感器时序数据 (如 `gyro_z: [-450.2, ...]`)，但擅长基于**结构化特征**进行推理。Kinematic Prompt 是两者之间的桥梁。

| 优点 | 缺点 |
|-----|-----|
| ✅ 灵活 + 个性化 | ❌ 延迟较高 (200-500ms) |
| ✅ 不会幻觉 (输入是验证过的特征) | ❌ 需调用 LLM API |
| ✅ 可处理规则外情况 | ❌ 成本 ($5-15/月) |
| ✅ 研究验证 (BoxingPro 192-312ms) | ❌ 仅适合挥杆后反馈 |

#### 方案 C: 挥杆后分析 (推荐, MVP Phase 1)

> **对应模式**: Mode 3: Full Speed (正常挥杆后分析)

```text
┌─────────────────────────────────────────────────────────────────────┐
│              MVP Phase 1: 挥杆后分析 (Mode 3: Full Speed)            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Step 1: 特征提取                                                   │
│  ─────────────────                                                  │
│  • MediaPipe 骨架检测 (33关键点)                                    │
│  • Mock IMU 相位检测 + 节奏计算                                     │
│  • Mock EMG 激活计算                                                │
│  • 6 条核心规则判断                                                 │
│                                                                     │
│  Step 2: Kinematic Prompt 生成                                      │
│  ───────────────────────────────                                    │
│  • 结构化特征 → 文本                                                │
│  • 包含: 阶段时间线、指标、触发规则、用户历史                       │
│                                                                     │
│  Step 3: LLM 反馈生成                                               │
│  ─────────────────────                                              │
│  • OpenAI API / Gemini 2.5 Flash                                    │
│  • 输出: 教练级反馈 + TTS 语音                                      │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

未来扩展 (Phase 2+):
• Mode 2: Slow Motion - 慢动作实时反馈
• 历史趋势追踪、训练计划生成
```

---

### 2.3 推荐架构详解 (方案 C)

**MVP Phase 1 流程** (对应 Mode 3: Full Speed):

| 步骤 | 职责 | 说明 |
|-----|------|-----|
| **Step 1** | 特征提取 + 规则判断 | MediaPipe + Mock IMU/EMG → 12个指标 + 6条规则 |
| **Step 2** | Kinematic Prompt 生成 | 结构化特征 → LLM 可理解的文本 |
| **Step 3** | LLM 反馈生成 | OpenAI/Gemini → 教练级反馈 + TTS |

**关键设计原则**:

1. **挥杆后分析**: MVP Phase 1 专注 Mode 3，挥杆完成后再处理
2. **特征先行**: 先提取结构化特征，再喂给 LLM (不是原始数据)
3. **简单优先**: 实时反馈 (Mode 2) 留到 Phase 2+

**MVP 阶段实现**:

```python
# 第1步: 规则引擎判断 (硬编码, <5ms)
def evaluate_rules(features: FusionResult) -> List[Rule]:
    triggered = []

    # P0: 严重问题
    if features.emg.timing_gap < -20:
        triggered.append(Rule(
            id="ARMS_BEFORE_CORE",
            severity="P0",
            evidence=f"gap={features.emg.timing_gap}ms"
        ))

    if features.vision.x_factor >= 35 and features.emg.core_activation < 0.5:
        triggered.append(Rule(
            id="FALSE_COIL",
            severity="P0",
            evidence=f"x_factor={features.vision.x_factor}°, core={features.emg.core_activation*100}%"
        ))

    # P1: 重要问题
    if features.vision.x_factor < 35:
        triggered.append(Rule(
            id="LOW_X_FACTOR",
            severity="P1",
            evidence=f"x_factor={features.vision.x_factor}°"
        ))

    # ... 更多规则

    return triggered

# 第2步: LLM 翻译 (可选, 50-200ms)
def translate_to_feedback(rules: List[Rule]) -> str:
    if not rules:
        return "这一杆不错！"

    # 优先级排序: P0 > P1 > P2
    rules.sort(key=lambda r: r.severity)
    top_rule = rules[0]

    # 预定义模板 (快速, 无需调用 LLM)
    templates = {
        "ARMS_BEFORE_CORE": "从核心启动，让身体带动手臂",
        "FALSE_COIL": "转肩看起来够了，但核心没发力",
        "LOW_X_FACTOR": "肩膀再多转一点",
    }

    return templates.get(top_rule.id, "注意动作细节")

# 第3步 (可选): AI 个性化解释
async def generate_personalized_feedback(rules: List[Rule], user_history: UserHistory) -> str:
    prompt = f"""
    用户本次挥杆问题: {rules}
    用户历史: 最近 10 次都有类似问题

    用一句话给出个性化建议 (中文):
    """
    return await call_llm(prompt)
```

**6 条核心规则 (MVP)**:

| 规则 ID | 严重度 | 条件 | 反馈模板 |
|--------|-------|------|---------|
| `ARMS_BEFORE_CORE` | P0 | `timing_gap < -20ms` | "从核心启动" |
| `FALSE_COIL` | P0 | `x_factor >= 35 AND core < 50%` | "核心没发力" |
| `LOW_X_FACTOR` | P1 | `x_factor < 35` | "肩膀再多转" |
| `FAST_TEMPO` | P1 | `downswing < 0.20s` | "上杆慢一点" |
| `SLOW_TEMPO` | P1 | `downswing > 0.40s` | "下杆果断点" |
| `EARLY_RELEASE` | P1 | `wrist_release < 40%` | "保持手腕角度" |

---

### 2.4 Kinematic Prompt 规范 (Layer 2)

Kinematic Prompt 是将计算特征转换为 LLM 可理解的结构化文本。这是让 LLM 能够进行生物力学推理的关键桥梁。

**Prompt 应包含的元素**:

| 元素 | 说明 | 示例 |
|-----|------|-----|
| **阶段时间线** | 各相位的起止时间 | Address: 0-200ms, Backswing: 200-700ms, ... |
| **关键指标** | 实测值 vs 标准范围 + 状态标记 | X-Factor: 42° (标准 35-55°) ✅ |
| **触发的规则** | Layer 1 检测到的问题 | `FALSE_COIL`, `LOW_X_FACTOR` |
| **用户历史** | 最近 N 次挥杆的重复问题 | "最近 10 次中 7 次出现核心激活不足" |
| **上下文约束** | 输出格式要求 | "用一句简洁的中文给出建议" |

**为什么不直接发送原始数据?**

```text
❌ 原始数据: gyro_z = [-12.3, -15.1, -450.2, -890.5, ...]
   → LLM 无法理解 1666Hz 时序数据的含义

✅ Kinematic Prompt: "Peak velocity = 890°/s (good, >800°/s threshold)"
   → LLM 理解这是一个达标的指标，可以进行推理
```

> **研究支持**: LLaSA (2024) 表明专门的 IMU 模型比通用 LLM 在传感器任务上好 2.6-12 倍，但通用 LLM 在**结构化特征推理**上表现良好。

---

### 2.5 模型选择指南

| 用途 | 推荐模型 | 延迟 | 成本 | 备注 |
|-----|---------|------|-----|------|
| **LLM 反馈生成** | Gemini 2.5 Flash | ~290ms | $0.15/$0.60 per 1M tokens | 最佳性价比，1M 上下文 |
| **LLM 备选** | OpenAI GPT-4o | ~300ms | $2.50/$10 per 1M tokens | 当前 MVP 使用 |
| **开源替代** | Qwen3-8B | 可变 | 自托管成本 | 需自建推理服务 |
| **姿态估计** | MediaPipe | 10-30ms | 免费 | 33 关键点检测 |

**成本估算** (按每月 300 次挥杆计算):

| 方案 | 特征提取 | LLM 调用 | 总成本 |
|-----|---------|---------|-------|
| MVP (OpenAI) | $0 | ~$5-10 | **$5-10/月** |
| 优化 (Gemini Flash) | $0 | ~$2-5 | **$2-5/月** |

---

### 2.6 研究来源

本架构基于以下 2024-2025 年研究:

| 研究 | 关键发现 | 链接 |
|-----|---------|------|
| **BoxingPro (2025)** | IMU + 视频 → Kinematic Prompts → LLM, 192-312ms 延迟 | MDPI Computers 14(21):4155 |
| **SportsGPT (2025)** | Qwen3-8B + RAG, 1.42ms 推理 | [arXiv](https://arxiv.org/abs/2506.05573) |
| **LLaSA (2024)** | 专用 IMU 模型比通用 LLM 好 2.6-12× | [arXiv](https://arxiv.org/abs/2406.14498) |
| **CaddieSet (CVPR 2025)** | 特征工程 + Random Forest 优于端到端深度学习 | [GitHub](https://github.com/damilab/CaddieSet) |
| **Multi-Sport Fusion (2025)** | 多模态传感器融合, 192-312ms 验证 | [Nature](https://www.nature.com/articles/s41598-025-12920-9) |

---

## 3. 标准与阈值来源 {#3-标准与阈值来源}

### 3.1 行业标准: TPI

**TPI (Titleist Performance Institute)** 是高尔夫行业的官方生物力学认证机构。

```text
┌────────────────────────────────────────────────────────────────┐
│                    TPI 机构简介                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  • 成立于 2003 年                                              │
│  • 全球 30,000+ 认证教练使用                                   │
│  • 基于对职业球员的实测数据                                    │
│  • 官网: https://www.mytpi.com                                 │
│                                                                │
├────────────────────────────────────────────────────────────────┤
│                    TPI 定义的标准                               │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  指标              │ 业余标准      │ 职业标准                  │
│  ─────────────────┼──────────────┼────────────────            │
│  X-Factor         │ > 35°        │ 42-55°                     │
│  Shoulder Turn    │ 85-100°      │ 90-100°                    │
│  Hip Turn         │ 40-55°       │ 45-55°                     │
│  Tempo Ratio      │ 2.5-3.5      │ 3:1                        │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

### 3.2 学术论文

#### Meister et al. (2011)

**论文**: "Rotational Biomechanics of the Elite Golf Swing: Benchmarks for Amateurs"
**期刊**: Journal of Applied Biomechanics, Vol. 27(3), pp. 242-251

**定义的标准**:

| 指标 | 职业球员平均值 | 来源 |
|-----|--------------|------|
| 骨盆旋转速度 | 477°/s ± 53°/s | 表 2 |
| 躯干旋转速度 | 552°/s ± 48°/s | 表 2 |
| S-Factor (肩部倾斜) | 30-40° | 图 4 |

**论文链接**: [PDF](https://waddengolfacademy.com/biomechanics/Rotational%20Biomechanics%20Meister%20Ladd.pdf)

#### Cheetham et al. (2008)

**论文**: "Comparison of Kinematic Sequence Parameters in the Golf Swings of High and Low Handicap Golfers"

**定义的标准**:

| 指标 | 描述 | 职业标准 |
|-----|------|---------|
| 运动链顺序 | 骨盆 → 躯干 → 手臂 → 球杆 | 正确顺序 |
| 核心→前臂时间差 | Core onset 早于 Forearm onset | 30-60ms |

**关键发现**: 职业球员的核心肌群比前臂早激活 30-60ms，业余球员往往相反或同时。

#### PMC Systematic Review (2022)

**论文**: PMC Systematic Review on Golf Biomechanics (92 篇论文 meta-analysis)
**链接**: [PMC9227529](https://pmc.ncbi.nlm.nih.gov/articles/PMC9227529/)

**综合定义**:

- 12 项核心指标的标准值
- 性别调整因子 (女性 X-Factor 平均低 11%)
- 年龄调整因子

---

### 3.3 标准如何应用

**从研究到规则的转化过程**:

```text
学术论文
    │
    │  Cheetham et al. (2008):
    │  "职业球员核心比前臂早激活 30-60ms"
    │
    ▼
阈值定义
    │
    │  正常: gap > 20ms (核心先)
    │  问题: gap < -20ms (前臂先)
    │
    ▼
规则编码
    │
    │  if timing_gap < -20:
    │      return "ARMS_BEFORE_CORE"
    │
    ▼
用户反馈
    │
    │  "从核心启动，让身体带动手臂"
```

**为什么 AI 不会"说错话"?**

```text
┌────────────────────────────────────────────────────────────────┐
│                    判断与翻译分离                               │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  判断层 (规则引擎):                                            │
│  ───────────────────                                           │
│  • 基于研究论文的固定阈值                                      │
│  • IF-THEN 逻辑，100% 可预测                                   │
│  • 不会"猜测"或"编造"                                          │
│                                                                │
│  翻译层 (LLM):                                                 │
│  ───────────────────                                           │
│  • 只负责把规则结果翻译成人话                                  │
│  • 输入是结构化的规则 ID，不是原始数据                        │
│  • 即使翻译略有不同，意思不会错                                │
│                                                                │
│  结论: AI 不做判断，只做翻译。判断由固定规则完成。             │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

## 4. 用户体验设计 {#4-用户体验设计}

### 4.1 用户界面

用户在手机 App 上看到的界面简洁明了:

```text
┌────────────────────────────────────────────────────────────────┐
│              用户手机界面                                       │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  FPS: 30  │  Score: 78  │  🔋 85%                        │  │
│  ├──────────────────────────────────────────────────────────┤  │
│  │                                                          │  │
│  │                                                          │  │
│  │           ┌─────────────────────────────────┐            │  │
│  │           │                                 │            │  │
│  │           │      [实时摄像头画面]           │            │  │
│  │           │                                 │            │  │
│  │           │         👤                      │            │  │
│  │           │        /│\   ← 半透明骨架       │            │  │
│  │           │        / \     (白色, 覆盖在身体上)          │  │
│  │           │                                 │            │  │
│  │           │      ↓ 红色箭头                 │            │  │
│  │           │      (指向需要调整的关节)        │            │  │
│  │           │                                 │            │  │
│  │           └─────────────────────────────────┘            │  │
│  │                                                          │  │
│  ├──────────────────────────────────────────────────────────┤  │
│  │                                                          │  │
│  │   X-Factor: 42° ✅    核心激活: 弱 ⚠️                    │  │
│  │                                                          │  │
│  │   [开始录制]  [设置]  [历史]                              │  │
│  │                                                          │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                │
├────────────────────────────────────────────────────────────────┤
│                    设计原则                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  1. 简洁: 不超过 3 个关键指标                                  │
│  2. 聚焦: 每次只指出 1-2 个问题                                │
│  3. 不干扰: 覆盖层半透明，不遮挡身体                           │
│  4. 可操作: 反馈告诉用户"怎么做"，不是"什么错"                 │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

**颜色编码**:

| 颜色 | 含义 | 示例 |
|-----|------|-----|
| 🟢 绿色 | 良好 | X-Factor: 45° ✅ |
| 🟡 黄色 | 需注意 | 核心激活: 弱 ⚠️ |
| 🔴 红色 | 问题 | 发力顺序: 错 ❌ |

---

### 4.2 语音反馈

**预录音频 (快速响应)**:

| 规则 | 语音内容 | 时长 |
|-----|---------|-----|
| `ARMS_BEFORE_CORE` | "从核心启动" | ~1s |
| `FALSE_COIL` | "核心没发力" | ~1s |
| `LOW_X_FACTOR` | "肩膀再多转一点" | ~1.2s |
| `FAST_TEMPO` | "上杆慢一点" | ~1s |
| `GOOD_SWING` | "这一杆不错！" | ~1s |

**动态 TTS (需要具体数值时)**:

```text
"X因子 32 度，不够"
"速度 1200，很不错"
"这一杆 85 分"
```

**优先级系统**:

```text
P0 (最先说): 严重问题 (ARMS_BEFORE_CORE, FALSE_COIL)
P1 (其次):   重要问题 (LOW_X_FACTOR, TEMPO)
P2 (最后):   优化建议 (BALANCE)

规则: 每次最多说 2 条反馈，避免信息过载
```

---

### 4.3 开发者工具 vs 用户界面

| 方面 | 用户界面 (App) | 开发者工具 (Rerun) |
|-----|---------------|-------------------|
| **目的** | 帮助用户改进挥杆 | 调试和验证算法 |
| **复杂度** | 简单 (1-3 个指标) | 复杂 (多流时间轴) |
| **数据展示** | 文字 + 颜色编码 | 波形图 + 多流同步 |
| **实时性** | 实时反馈 | 离线分析 |
| **用户** | 高尔夫球手 | 工程师 |

**为什么用户不看 Rerun?**

1. **太复杂**: 普通用户不理解 EMG 波形图
2. **不可操作**: 知道"核心激活 485ms"不知道怎么改
3. **干扰练习**: 分析数据会打断挥杆节奏
4. **不需要**: 用户需要的是"怎么改"，不是"数据是什么"

**用户需要的反馈**:

```text
❌ "你的核心肌群在 485ms 时激活，前臂在 540ms 时激活，
    时间差为 +55ms，符合 Cheetham et al. (2008) 的标准"

✅ "这一杆不错！核心发力到位了"
```

---

## 附录

### A. 术语表

| 术语 | 英文 | 定义 |
|-----|------|-----|
| X-Factor | X-Factor | 肩膀与髋部的旋转角度差 |
| S-Factor | S-Factor (Shoulder Obliquity) | 肩部倾斜角度 |
| O-Factor | O-Factor (Pelvis Obliquity) | 骨盆倾斜角度 |
| Timing Gap | Timing Gap | 核心与前臂激活的时间差 |
| MVC | Maximum Voluntary Contraction | 最大自主收缩 (EMG 基准) |

### B. 相关文档

- [模块化架构](modular-architecture.md) - 系统模块详细设计
- [实时反馈规格](../specs/real-time-feedback.md) - 反馈时延和模式详解
- [生物力学基准](../../prerequisites/foundations/biomechanics-benchmarks.md) - 完整阈值表
- [传感器指标映射](./sensor-metric-mapping.md) - 数据计算公式

---

文档版本: v1.2 | 作者: Movement Chain AI Team | 最后更新: 2025-12-23

**v1.2 更新**: 新增 BLE 时间抖动警告、Sensor Hub 架构、ESP32 源端时间戳方案

**v1.1 更新**: 新增三层混合架构、Kinematic Prompts 规范、模型选择指南、研究来源
