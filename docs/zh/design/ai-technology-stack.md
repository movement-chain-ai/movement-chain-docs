# 端到端 AI 技术架构

> **文档目的**: 全面梳理从传感器数据采集到用户反馈输出的完整 AI 技术栈，明确每个环节可用的技术方案
>
> **阅读对象**: 产品经理、算法工程师、技术投资人
>
> **关键价值**: 帮助团队理解"端到端每个地方可以用到哪些技术"

---

## 核心原则：AI 服务于产品目标

Movement Chain AI 的目标是帮助用户改善高尔夫挥杆，而不是为了用 AI 而用 AI。

**适合我们的 AI：**

- 姿态估计、动作分类、多模态融合
- 个性化反馈、训练计划生成
- 异常检测、伤害预防

**不适合我们的 AI：**

- 图片/视频生成 (Stable Diffusion, Sora) — 我们分析真实动作，不生成假的
- 纯聊天机器人 — 用户需要视觉反馈，不是聊天
- 通用图像识别 — 我们需要专门的人体姿态

---

## 核心架构：端到端数据流

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                          端到端 AI 数据流架构                                      │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐      │
│  │ 数据采集  │ → │ 骨架提取  │ → │ 时间同步  │ → │ 特征提取  │ → │ 分析引擎  │      │
│  └──────────┘   └──────────┘   └──────────┘   └──────────┘   └──────────┘      │
│       │              │              │              │              │             │
│       ▼              ▼              ▼              ▼              ▼             │
│  ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐      │
│  │ 摄像头    │   │MediaPipe │   │ 插值对齐  │   │ 关节角度  │   │ 规则引擎  │      │
│  │ IMU      │   │Pose      │   │ 降采样    │   │ 挥杆节奏  │   │    或     │      │
│  │ EMG      │   │          │   │          │   │ 肌肉激活  │   │ ML分类器  │      │
│  └──────────┘   └──────────┘   └──────────┘   └──────────┘   └──────────┘      │
│                                                                   │             │
│                                                                   ▼             │
│                                                            ┌──────────┐        │
│                                                            │  输出层   │        │
│                                                            └──────────┘        │
│                                                                   │             │
│                      ┌────────────────┬────────────────┬─────────┴────────┐    │
│                      ▼                ▼                ▼                  ▼    │
│               ┌──────────┐     ┌──────────┐     ┌──────────┐      ┌──────────┐ │
│               │ 骨架叠加  │     │ Ghost对比 │     │ 语音反馈  │      │ AR 指导  │ │
│               │ (第三人称)│     │ (幽灵路径)│     │ (TTS)    │      │ (第一人称)│ │
│               └──────────┘     └──────────┘     └──────────┘      └──────────┘ │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 🔑 每层 AI 应用全景图

> **核心价值**: 明确"端到端每个环节可以用哪些 AI"，将 7 大 AI 场景映射到 6 层架构

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    7 大 AI 场景 × 6 层架构 映射表                                  │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   架构层           可用 AI 场景                      MVP    Phase 2   Phase 3   │
│   ═══════════════════════════════════════════════════════════════════════════   │
│                                                                                  │
│   第1层            ┌─────────────────────────────────────────────────────────┐  │
│   数据采集         │ 🔸 暂无直接 AI，但数据质量影响所有下游 AI               │  │
│                    │ 🔮 未来: 智能采样、自适应帧率 (运动检测触发)            │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
│   第2层            ┌─────────────────────────────────────────────────────────┐  │
│   骨架提取         │ ✅ 场景1: 姿态估计 (Pose Estimation)                    │  │
│                    │    MVP: MediaPipe Pose (75% AP)                         │  │
│                    │    Phase 2: RTMPose (78% AP)                            │  │
│                    │    Phase 3: ViTPose++ (81.1% AP, SOTA)                  │  │
│                    │                                                          │  │
│                    │ 💡 这是 100% AI 驱动的层！                               │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
│   第3层            ┌─────────────────────────────────────────────────────────┐  │
│   时间同步         │ 🔸 主要是算法层 (插值、降采样)                          │  │
│                    │ 🔮 可选 AI 增强:                                        │  │
│                    │    • 智能事件检测 (识别击球瞬间作为同步锚点)             │  │
│                    │    • 运动阶段识别 (上杆/下杆/送杆 自动分割)              │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
│   第4层            ┌─────────────────────────────────────────────────────────┐  │
│   特征提取         │ ✅ 场景3: 多模态融合 (Multimodal Fusion)                │  │
│                    │    MVP: Early Fusion 特征拼接 (numpy)                   │  │
│                    │    Phase 2: 加权融合、置信度融合                        │  │
│                    │    Phase 3: Transformer Cross-Attention                 │  │
│                    │                                                          │  │
│                    │ 🔮 可选: 深度学习特征提取替代手工特征                    │  │
│                    │    • 用 CNN 从原始信号学习特征 (需要标注数据)            │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
│   第5层            ┌─────────────────────────────────────────────────────────┐  │
│   分析引擎         │ ✅ 场景2: 动作分类 (Action Classification)              │  │
│                    │    MVP: 规则引擎 IF-THEN (无需数据)                     │  │
│                    │    Phase 2-3: ML 分类器 (RandomForest → CNN)            │  │
│                    │                                                          │  │
│                    │ ✅ 场景7: 异常检测 (Anomaly Detection)                  │  │
│                    │    MVP: 简单统计阈值                                    │  │
│                    │    Phase 2: Autoencoder 无监督检测                      │  │
│                    │    Phase 3: LSTM 时序异常检测                           │  │
│                    │                                                          │  │
│                    │ 💡 EMG 差异化: 核心代偿、发力时序 — 竞品无法提供！       │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
│   第6层            ┌─────────────────────────────────────────────────────────┐  │
│   输出反馈         │ ✅ 场景4: LLM 教练反馈                                  │  │
│                    │    Phase 2: GPT-4/Claude 生成个性化自然语言反馈         │  │
│                    │    成本: ~$0.01/次                                      │  │
│                    │                                                          │  │
│                    │ ✅ 场景5: 训练计划生成                                  │  │
│                    │    Phase 2: LLM + 规则模板 → 个性化场下训练              │  │
│                    │                                                          │  │
│                    │ ✅ 场景6: 视频理解 LLM                                  │  │
│                    │    Phase 4: GPT-4V/Gemini 直接"看"视频并分析            │  │
│                    │    成本: ~$0.05/次 (实验性)                              │  │
│                    │                                                          │  │
│                    │ 🔮 Ghost 生成: AI 可用于个性化理想挥杆生成               │  │
│                    └─────────────────────────────────────────────────────────┘  │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### AI 场景 × 架构层 速查表

| AI 场景 | 应用层 | MVP 实现 | Phase 2-3 升级 | 核心价值 |
|--------|-------|---------|---------------|---------|
| **1. 姿态估计** | 第2层 骨架提取 | MediaPipe | ViTPose++ | 从图像→33关节点 |
| **2. 动作分类** | 第5层 分析引擎 | 规则引擎 | ML 分类器 | 识别挥杆问题类型 |
| **3. 多模态融合** | 第4层 特征提取 | 特征拼接 | Transformer | 三模态→统一表示 |
| **4. LLM 教练** | 第6层 输出反馈 | - | GPT-4/Claude | 自然语言反馈 |
| **5. 训练计划** | 第6层 输出反馈 | - | LLM+模板 | 个性化场下训练 |
| **6. 视频理解** | 第6层 输出反馈 | - | GPT-4V | 直接看视频分析 |
| **7. 异常检测** | 第5层 分析引擎 | 阈值 | LSTM | 疲劳/伤害预警 |

### AI 功能优先级矩阵

```text
价值高 ▲
       │
       │  ┌──────────────┐     ┌──────────────┐
       │  │ LLM教练反馈  │     │ 多模态融合   │
       │  │ Phase 2      │     │ Phase 1-2    │
       │  │ API调用即可  │     │ 核心差异化   │
       │  └──────────────┘     └──────────────┘
       │          ⭐⭐⭐⭐              ⭐⭐⭐⭐⭐
       │
       │  ┌──────────────┐     ┌──────────────┐
       │  │ 训练计划生成 │     │ 动作分类AI  │
       │  │ Phase 2      │     │ Phase 2-3    │
       │  │ 结合LLM      │     │ 需要训练数据 │
       │  └──────────────┘     └──────────────┘
       │          ⭐⭐⭐               ⭐⭐⭐⭐
       │
       │  ┌──────────────┐     ┌──────────────┐
       │  │ 疲劳/异常检测│     │ 视频理解LLM │
       │  │ Phase 2      │     │ Phase 3+     │
       │  │ EMG独特价值  │     │ 前沿研究     │
       │  └──────────────┘     └──────────────┘
       │          ⭐⭐⭐               ⭐⭐
价值低 ▼
       ─────────────────────────────────────────►
                 实现容易                 实现难
```

### 每层 AI 密度评估

```text
            AI 密度
第1层 数据采集    ░░░░░░░░░░  0%   纯硬件层
第2层 骨架提取    ██████████ 100%  完全 AI 驱动
第3层 时间同步    ░░░░░░░░░░  0%   算法层 (可选 AI)
第4层 特征提取    ████░░░░░░  40%  手工+AI 融合
第5层 分析引擎    ████████░░  80%  规则→ML 演进
第6层 输出反馈    ██████░░░░  60%  模板→LLM 演进
```

---

## 第一层：数据采集

### 三模态传感器架构

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           三模态数据采集层                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ┌───────────────────┐  ┌───────────────────┐  ┌───────────────────┐          │
│   │    Vision 视觉     │  │     IMU 惯性      │  │     EMG 肌电      │          │
│   │    (摄像头)        │  │    (手腕传感器)    │  │    (肌肉贴片)     │          │
│   ├───────────────────┤  ├───────────────────┤  ├───────────────────┤          │
│   │ 采样率: 30 fps     │  │ 采样率: 100-200Hz │  │ 采样率: 200-1000Hz│          │
│   │ 延迟: ~33ms       │  │ 延迟: <10ms       │  │ 延迟: <5ms        │          │
│   │ 输出: RGB 图像     │  │ 输出: 6轴数据     │  │ 输出: 电压信号    │          │
│   ├───────────────────┤  ├───────────────────┤  ├───────────────────┤          │
│   │ 测量内容:          │  │ 测量内容:          │  │ 测量内容:          │          │
│   │ • 全身姿态         │  │ • 手腕角速度       │  │ • 肌肉激活程度     │          │
│   │ • 33个关节点       │  │ • 加速度           │  │ • 发力时序        │          │
│   │ • 挥杆平面         │  │ • 精确击球时机     │  │ • 疲劳状态        │          │
│   ├───────────────────┤  ├───────────────────┤  ├───────────────────┤          │
│   │ 优势:             │  │ 优势:             │  │ 优势:             │          │
│   │ ✅ 全身可见        │  │ ✅ 高时间精度      │  │ ✅ 内部状态可见    │          │
│   │ ✅ 用户无感        │  │ ✅ 不受光照影响    │  │ ✅ 独特差异化      │          │
│   ├───────────────────┤  ├───────────────────┤  ├───────────────────┤          │
│   │ 劣势:             │  │ 劣势:             │  │ 劣势:             │          │
│   │ ❌ 遮挡问题        │  │ ❌ 单点数据        │  │ ❌ 需要接触皮肤    │          │
│   │ ❌ 帧率限制        │  │ ❌ 累积漂移        │  │ ❌ 信噪比挑战      │          │
│   └───────────────────┘  └───────────────────┘  └───────────────────┘          │
│                                                                                  │
│   🔑 关键洞察: 单模态准确率 ~70-85%，三模态融合后可达 95%+                          │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 数据采集技术选型

| 模态 | 硬件方案 | SDK/驱动 | 状态 |
|-----|---------|---------|------|
| Vision | 手机摄像头 / 外置相机 | iOS AVFoundation / Android CameraX | ✅ 成熟 |
| IMU | LSM6DSV16X (ADR-0002) | ESP-IDF 驱动 | ✅ 选型完成 |
| EMG | TBD (2通道起步) | NeuroKit2 处理 | 🔧 Phase 2 |

---

## 第二层：骨架提取 (Pose Estimation)

### AI 模型升级路径

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                         姿态估计模型演进路径                                        │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   Phase 1 (MVP)              Phase 2                    Phase 3                 │
│   ┌──────────────┐          ┌──────────────┐          ┌──────────────┐         │
│   │ MediaPipe    │    →     │  RTMPose     │    →     │  ViTPose++   │         │
│   │    Pose      │          │              │          │              │         │
│   ├──────────────┤          ├──────────────┤          ├──────────────┤         │
│   │ 准确率: ~75% │          │ 准确率: ~78% │          │ 准确率: 81.1%│         │
│   │ 速度: 30fps+ │          │ 速度: 25fps  │          │ 速度: 需GPU  │         │
│   │ 部署: 开箱用 │          │ 部署: 需配置 │          │ 部署: 服务器 │         │
│   └──────────────┘          └──────────────┘          └──────────────┘         │
│                                                                                  │
│   SDK/API:                                                                       │
│   ├── MediaPipe: pip install mediapipe (3行代码)                                │
│   ├── RTMPose: pip install mmpose (需要配置)                                    │
│   └── ViTPose++: GitHub 源码 (需要训练/微调)                                     │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 骨架提取输出格式

```python
# MediaPipe Pose 输出: 33个关节点
{
    "frame_id": 1,
    "timestamp_ms": 33.3,
    "landmarks": [
        {"id": 0, "name": "nose", "x": 0.512, "y": 0.285, "z": 0.001, "visibility": 0.99},
        {"id": 11, "name": "left_shoulder", "x": 0.421, "y": 0.412, "z": -0.052, "visibility": 0.97},
        # ... 共33个点
    ]
}
```

---

## 第三层：时间同步

### 多模态对齐策略

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                            时间同步策略                                           │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   问题: 三种传感器采样率不同，必须对齐才能正确分析                                   │
│                                                                                  │
│   原始数据流:                                                                     │
│   Vision:  |---F1---F2---F3---F4---F5---|  (30 fps, 每33ms一帧)                  │
│   IMU:     |*-*-*-*-*-*-*-*-*-*-*-*-*-*|  (100 Hz, 每10ms)                       │
│   EMG:     |********************...*****|  (200 Hz, 每5ms)                       │
│                                                                                  │
│   同步后 (对齐到 Vision 时间轴):                                                   │
│   统一时间轴: |--T1--T2--T3--T4--T5--|                                           │
│                 ↓     ↓     ↓     ↓     ↓                                        │
│   Vision:      F1    F2    F3    F4    F5   (原生帧)                             │
│   IMU:         I1    I2    I3    I4    I5   (线性插值)                           │
│   EMG:         E1    E2    E3    E4    E5   (降采样+RMS包络)                      │
│                                                                                  │
│   技术实现: numpy.interp() 线性插值                                               │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 第四层：特征提取

### 各模态特征映射

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           特征提取层                                              │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │                        Vision 特征                                       │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │ 输入: 33个关节点坐标 (x, y, z, visibility)                               │   │
│   │                                                                          │   │
│   │ 提取特征:                                                                │   │
│   │ ├── 肩膀旋转角度 (shoulder_rotation): 上杆顶点应 >85°                    │   │
│   │ ├── 髋部旋转角度 (hip_rotation): 应比肩膀小，约 45°                      │   │
│   │ ├── X-因子 (x_factor): 肩-髋分离角，动力来源                             │   │
│   │ ├── 左肘角度 (left_elbow_angle): 保持伸直 >160°                         │   │
│   │ └── 脊柱倾斜 (spine_tilt): 应保持稳定                                    │   │
│   │                                                                          │   │
│   │ 技术: math.atan2() 计算角度，纯数学运算                                   │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │                         IMU 特征                                         │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │ 输入: gyro_z (角速度), accel (加速度)                                    │   │
│   │                                                                          │   │
│   │ 提取特征:                                                                │   │
│   │ ├── 峰值角速度 (peak_angular_velocity): 击球力量指标，理想 >1200°/s      │   │
│   │ ├── 上杆顶点时间 (top_of_backswing): 角速度由负转正的点                   │   │
│   │ ├── 击球时间 (impact_time): 角速度峰值时刻                               │   │
│   │ └── 节奏比 (tempo_ratio): 上杆/下杆时间比，理想 3:1                       │   │
│   │                                                                          │   │
│   │ 技术: numpy 信号处理，零点检测                                            │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │                         EMG 特征                                         │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │ 输入: 原始肌电信号 (微伏级)                                               │   │
│   │                                                                          │   │
│   │ 处理流程: 原始信号 → 清洗 → RMS包络 → 激活百分比                          │   │
│   │                                                                          │   │
│   │ 提取特征:                                                                │   │
│   │ ├── 核心激活 (core_activation): 下杆阶段平均激活，应 >50%                 │   │
│   │ ├── 前臂激活 (forearm_activation): 不应过高 (<60%)                       │   │
│   │ ├── 激活时序 (activation_sequence): 核心应先于前臂激活                    │   │
│   │ └── 疲劳指标 (fatigue_index): 频率下降、振幅不稳                         │   │
│   │                                                                          │   │
│   │ 技术: NeuroKit2 (pip install neurokit2)                                  │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 第五层：分析引擎

### 规则引擎 vs ML 分类器

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                     分析引擎: 两种实现路径                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ┌─────────────────────────────────┐  ┌─────────────────────────────────┐      │
│   │      方案 A: 规则引擎            │  │      方案 B: ML 分类器           │      │
│   │      (MVP 推荐) ✅               │  │      (Phase 2-3)                │      │
│   ├─────────────────────────────────┤  ├─────────────────────────────────┤      │
│   │                                  │  │                                  │      │
│   │  实现方式:                        │  │  实现方式:                        │      │
│   │  IF-THEN 硬编码规则              │  │  训练数据 → 模型 → 预测           │      │
│   │                                  │  │                                  │      │
│   │  示例:                           │  │  示例:                           │      │
│   │  IF 肩部旋转 < 85°              │  │  model = RandomForest()          │      │
│   │    THEN 问题="转肩不足"          │  │  model.fit(X_train, y_train)     │      │
│   │                                  │  │  problem = model.predict(X)      │      │
│   │  IF 核心激活 < 50%              │  │                                  │      │
│   │    AND 前臂激活 > 60%           │  │                                  │      │
│   │    THEN 问题="手臂代偿"          │  │                                  │      │
│   │                                  │  │                                  │      │
│   ├─────────────────────────────────┤  ├─────────────────────────────────┤      │
│   │ 优点:                            │  │ 优点:                            │      │
│   │ ✅ 快速开发，无需数据            │  │ ✅ 更准确，可处理边界情况         │      │
│   │ ✅ 完全可解释                    │  │ ✅ 自动学习复杂模式              │      │
│   │ ✅ 易于调试和调整                │  │ ✅ 可个性化适应                   │      │
│   │                                  │  │                                  │      │
│   │ 缺点:                            │  │ 缺点:                            │      │
│   │ ❌ 阈值需手动调整                │  │ ❌ 需要500-1000标注样本           │      │
│   │ ❌ 无法适应个人差异              │  │ ❌ 需要ML专业知识                 │      │
│   │ ❌ 边界情况处理困难              │  │ ❌ 黑盒，难以解释                 │      │
│   │                                  │  │                                  │      │
│   ├─────────────────────────────────┤  ├─────────────────────────────────┤      │
│   │ 适用阶段: MVP, Phase 1           │  │ 适用阶段: Phase 2-3              │      │
│   │ 工作量: 1-2 周                   │  │ 工作量: 需数据收集+训练          │      │
│   │ SDK: 纯 Python IF-THEN          │  │ SDK: sklearn, pytorch           │      │
│   └─────────────────────────────────┘  └─────────────────────────────────┘      │
│                                                                                  │
│   🔑 推荐路径: MVP 用规则引擎验证产品，同时收集数据，Phase 2 训练 ML 分类器        │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 规则引擎核心规则清单

| # | 规则名称 | 条件 | 问题描述 | 扣分 | 来源 |
|---|---------|------|---------|-----|------|
| 1 | 转肩不足 | shoulder_rotation < 85° | 上杆转肩不够 | -15 | Vision |
| 2 | 髋部受限 | hip_rotation < 40° | 髋部旋转不足 | -10 | Vision |
| 3 | X因子过小 | x_factor < 35° | 肩髋分离不够 | -10 | Vision |
| 4 | 左肘弯曲 | left_elbow_angle < 160° | 左臂未保持伸直 | -10 | Vision |
| 5 | 节奏过快 | tempo_ratio < 2.5 | 下杆太急 | -10 | IMU |
| 6 | 节奏过慢 | tempo_ratio > 4.0 | 下杆犹豫 | -5 | IMU |
| 7 | 速度不足 | peak_velocity < 800°/s | 挥杆力量弱 | -5 | IMU |
| **8** | **核心代偿** | core < 50% AND forearm > 60% | **手臂代替核心发力** | **-20** | **EMG** |
| **9** | **时序错误** | forearm_onset < core_onset | **发力顺序错误** | **-15** | **EMG** |

> 注: 规则 8、9 是 EMG 独特价值，竞品无法提供

---

## 第六层：输出反馈

### 四种输出模态

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           输出反馈层：四种模态                                     │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │  1. 第三人称骨架叠加 (Training Analysis)                                 │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                          │   │
│   │   用途: 事后回放分析，理解自己做了什么                                     │   │
│   │                                                                          │   │
│   │   ┌───────────────────────────────────────────────────────────┐         │   │
│   │   │                                                            │         │   │
│   │   │         ○ ← 头部追踪                                       │         │   │
│   │   │        /│\                                                 │         │   │
│   │   │       / │ \ ← 肩线角度: 95° ✅                             │         │   │
│   │   │      🟢 │ 🟢 ← 绿色=正确位置                               │         │   │
│   │   │         │                                                  │         │   │
│   │   │        ┌┴┐ ← 髋部旋转: 45°                                 │         │   │
│   │   │       /   \                                                │         │   │
│   │   │      🟢   🟢                                               │         │   │
│   │   │                                                            │         │   │
│   │   │  [摄像头实时画面作为背景]                                   │         │   │
│   │   │                                                            │         │   │
│   │   │  ┌──────────────────────────────────────────────────────┐ │         │   │
│   │   │  │ 速度: 95mph │ 节奏: 3:1 │ 评分: 82 │ 🔴 核心不足检测 │ │         │   │
│   │   │  └──────────────────────────────────────────────────────┘ │         │   │
│   │   └───────────────────────────────────────────────────────────┘         │   │
│   │                                                                          │   │
│   │   技术: OpenCV + MediaPipe 绘制                                          │   │
│   │   阶段: MVP Phase 1 ✅                                                   │   │
│   │                                                                          │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │  2. Ghost 幽灵对比 (Ideal vs Actual)                                     │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                          │   │
│   │   用途: 显示理想挥杆轨迹，用户尝试与幽灵重合                               │   │
│   │                                                                          │   │
│   │   ┌───────────────────────────────────────────────────────────┐         │   │
│   │   │                                                            │         │   │
│   │   │      🔴 用户骨架          🟢 Ghost 理想骨架                │         │   │
│   │   │        ○                       ○                          │         │   │
│   │   │       /│\                     /│\                         │         │   │
│   │   │      / │ \                   / │ \                        │         │   │
│   │   │     ●  │  ●                 ◇  │  ◇  ← 半透明绿色        │         │   │
│   │   │        │                       │                          │         │   │
│   │   │       /|\                     /|\                         │         │   │
│   │   │      / | \                   / | \                        │         │   │
│   │   │                                                            │         │   │
│   │   │   偏差: 肩膀位置差 15°，需向左旋转                          │         │   │
│   │   │                                                            │         │   │
│   │   └───────────────────────────────────────────────────────────┘         │   │
│   │                                                                          │   │
│   │   Ghost 来源:                                                            │   │
│   │   ├── 职业球员骨架缩放 (GolfDB 数据集)                                   │   │
│   │   ├── 用户历史最佳挥杆                                                   │   │
│   │   └── 教练演示录制                                                       │   │
│   │                                                                          │   │
│   │   技术: OpenCV 半透明叠加                                                │   │
│   │   阶段: Phase 2                                                          │   │
│   │                                                                          │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │  3. 语音反馈 (Voice Feedback)                                            │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                          │   │
│   │   用途: 即时语音提示，用户无需看屏幕                                       │   │
│   │                                                                          │   │
│   │   触发时机:                                                              │   │
│   │   ├── 挥杆完成后: "82分，节奏很好"                          (延迟<500ms) │   │
│   │   ├── 检测到问题: "注意从内侧下杆"                          (延迟<300ms) │   │
│   │   ├── 连续改善: "进步了！比上次快5英里"                     (延迟<1s)   │   │
│   │   ├── EMG 异常: "核心发力不足，注意收紧腹部"                (延迟<500ms) │   │
│   │   └── 疲劳预警: "已练习30分钟，肌肉疲劳，建议休息"          (非实时)    │   │
│   │                                                                          │   │
│   │   技术:                                                                  │   │
│   │   ├── Flutter: flutter_tts (系统 TTS)                                   │   │
│   │   └── 高级: GPT-4/Claude 生成个性化反馈 (~$0.01/次)                      │   │
│   │                                                                          │   │
│   │   阶段: MVP Phase 1 (基础), Phase 2 (LLM 增强)                           │   │
│   │                                                                          │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │  4. 第一人称 AR 指导 (Egocentric Guidance)                               │   │
│   ├─────────────────────────────────────────────────────────────────────────┤   │
│   │                                                                          │   │
│   │   用途: 用户第一视角看到指导，实时纠正动作                                 │   │
│   │                                                                          │   │
│   │   视觉元素:                                                              │   │
│   │   ├── 幽灵路径 (Ghost Path): 手臂/球杆的理想轨迹                         │   │
│   │   ├── 约束区域 (Constraint Zone): "手不该进入红色区域"                    │   │
│   │   ├── 偏差箭头 (Deviation Arrow): 指示纠正方向                           │   │
│   │   └── HUD 显示: 关键数据悬浮                                             │   │
│   │                                                                          │   │
│   │   硬件依赖:                                                              │   │
│   │   ├── Apple Vision Pro                                                   │   │
│   │   ├── Meta Quest                                                         │   │
│   │   └── 专业 AR 眼镜 (CaddieVision)                                        │   │
│   │                                                                          │   │
│   │   阶段: Phase 4 (依赖硬件生态成熟)                                        │   │
│   │                                                                          │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 第三人称 vs 第一人称对比

| 维度 | 第三人称骨架叠加 | 第一人称 AR 指导 |
|-----|----------------|-----------------|
| **视角** | 外部相机看用户 | 用户自己的视角 |
| **目的** | 分析 — "我做了什么" | 指导 — "我该怎么做" |
| **显示** | 骨架线条叠加视频 | 幽灵路径、偏差箭头 |
| **时机** | 事后回放 | 实时提示 |
| **复杂度** | ⭐⭐ | ⭐⭐⭐⭐⭐ |
| **阶段** | MVP | Phase 4 |

---

## 7 大 AI 应用场景

### 场景与技术栈映射

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                      7 大 AI 应用场景 (2025)                                      │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   场景              当前状态         2025 目标            技术栈                   │
│   ─────────────────────────────────────────────────────────────────────────     │
│                                                                                  │
│   1. 姿态估计        MediaPipe        ViTPose++ 81.1%     mediapipe → mmpose    │
│      Pose Est.       ~75% AP          SOTA                                       │
│                                                                                  │
│   2. 动作分类        规则引擎          ML 分类器            sklearn → pytorch    │
│      Action Class.   IF-THEN          92%+ 准确率          参考: GolfMate        │
│                                                                                  │
│   3. 多模态融合      Early Fusion     Transformer          numpy → pytorch      │
│      Multimodal      特征拼接         Cross-Attention      核心差异化！           │
│                                                                                  │
│   4. LLM 教练        无               GPT-4/Claude         OpenAI/Anthropic API │
│      LLM Coach                        个性化反馈           ~$0.01/次             │
│                                                                                  │
│   5. 训练计划        无               AI 生成              LLM + 规则模板         │
│      Training Plan                    个性化计划                                  │
│                                                                                  │
│   6. 视频理解        无               多模态 LLM           GPT-4V/Gemini         │
│      Video LLM                        直接"看"视频         ~$0.05/次             │
│                                                                                  │
│   7. 异常检测        简单阈值          LSTM Autoencoder    scipy → pytorch       │
│      Anomaly Det.                     疲劳/伤害预警        EMG 独特价值！          │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 各场景详细技术方案

#### 场景 1: 姿态估计

| 模型 | 准确率 | 速度 | 部署难度 | 推荐阶段 |
|-----|-------|------|---------|---------|
| MediaPipe Pose | ~75% AP | 30fps+ 实时 | `pip install mediapipe` | MVP ✅ |
| RTMPose | ~78% AP | 25fps | 需配置 mmpose | Phase 2 |
| ViTPose++ | 81.1% AP (COCO SOTA) | 需GPU | 需服务器 | Phase 3 |

#### 场景 2: 动作分类

```text
演进路径:
Phase 1: 规则引擎 (IF-THEN)
   ↓
Phase 2: 收集 500-1000 标注挥杆
   ↓
Phase 3: 训练分类器 (RandomForest → CNN)
   ↓
未来: Explainable Embedding (参考 GolfMate)
```

#### 场景 4: LLM 教练反馈

**输入 Prompt 示例:**

```json
{
  "user": {"name": "小王", "handicap": 18, "goal": "降到15"},
  "swing_analysis": {
    "problems": ["核心激活不足", "下杆节奏快"],
    "emg_data": {"core": 35, "forearm": 78},
    "improvement_vs_last_week": "+5%"
  }
}
```

**LLM 输出:**

> "小王，今天练习比上周进步5%，很棒！我注意到你的核心发力只有35%，但手臂用力78%——这说明你在用手臂代替身体发力。试试这个练习：击球前先做3个俄罗斯转体，感受核心发力的感觉，然后再挥杆。"

---

## 分阶段 AI 整合路线

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                         AI 整合路线图                                             │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   Phase 1: MVP (1-2月)                          AI 占比: ~20%                    │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 姿态估计: MediaPipe Pose (开箱即用)                                    │   │
│   │ • 分析引擎: 规则引擎 IF-THEN (自己写)                                    │   │
│   │ • 融合方式: Early Fusion 特征拼接 (numpy)                                │   │
│   │ • 输出: 骨架叠加 + 评分 + 基础语音 (OpenCV + TTS)                        │   │
│   │                                                                          │   │
│   │ 验证点: MediaPipe 能否稳定提取高尔夫骨架？规则反馈是否有意义？             │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                      ↓                                          │
│   Phase 2: AI 增强 (3-6月)                      AI 占比: ~50%                    │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • LLM 教练: GPT-4/Claude API 个性化反馈 (~$0.01/次)                      │   │
│   │ • 训练计划: LLM + 规则模板自动生成                                       │   │
│   │ • 疲劳检测: EMG 统计分析 (scipy)                                        │   │
│   │ • Ghost: 职业骨架缩放 + 用户最佳挥杆                                     │   │
│   │ • 数据收集: 为 Phase 3 准备标注数据                                      │   │
│   │                                                                          │   │
│   │ 新增功能: 自然语言反馈、场下训练推荐、疲劳预警、幽灵对比                   │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                      ↓                                          │
│   Phase 3: 深度 AI (6-12月)                     AI 占比: ~80%                    │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 动作分类器: 训练自定义 CNN/Transformer (pytorch)                       │   │
│   │ • 姿态升级: RTMPose/ViTPose (mmpose)                                    │   │
│   │ • 异常检测: LSTM Autoencoder 时序分析 (pytorch)                         │   │
│   │ • 融合升级: Transformer Cross-Attention                                  │   │
│   │                                                                          │   │
│   │ 数据需求: 500-1000 个教练标注的挥杆样本                                   │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                      ↓                                          │
│   Phase 4: 前沿探索 (12+月)                     AI 占比: 前沿研究               │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 视频理解 LLM: GPT-4V/Gemini 直接分析视频                               │   │
│   │ • 第一人称 AR: Apple Vision Pro 集成                                    │   │
│   │ • 联邦学习: 隐私保护个性化训练                                           │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## SDK/API 可用性总览

| 组件 | 可用性 | 工具/包 | 成本 | 代码量 |
|-----|-------|--------|------|-------|
| **姿态估计** | ✅ 开箱即用 | `mediapipe` | 免费 | 3行 |
| **EMG 处理** | ✅ 开箱即用 | `neurokit2` | 免费 | 1行 |
| **时间同步** | ✅ 标准库 | `numpy.interp()` | 免费 | 5行 |
| **特征提取** | 🛠️ 自己写 | `math`, `numpy` | 免费 | ~100行 |
| **规则引擎** | 🛠️ 自己写 | 纯 Python | 免费 | ~200行 |
| **Ghost 生成** | 🛠️ 自己写 | `numpy`, `opencv` | 免费 | ~50行 |
| **可视化** | ✅ 现成 | `opencv`, `mediapipe` | 免费 | ~30行 |
| **语音反馈** | ✅ 现成 | `flutter_tts` | 免费 | 系统TTS |
| **LLM 反馈** | ✅ API | OpenAI/Claude | ~$0.01/次 | API调用 |
| **ML 分类器** | 🔧 需训练 | `sklearn`/`pytorch` | 免费 | 需数据 |

**图例:**

- ✅ = 开箱即用，pip install 即可
- 🔧 = 有开源库，需要配置或训练
- 🛠️ = 自己写代码，但逻辑简单

---

## OpenSim 生物力学整合方案

> **核心价值**: OpenSim 是斯坦福大学开发的开源生物力学仿真平台，可为 Movement Chain AI 提供"运动科学级"分析能力

### OpenSim 生态系统概览

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                         OpenSim 生态系统                                          │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ┌───────────────────────────────────────────────────────────────────────────┐ │
│   │                        OpenSim Core                                        │ │
│   │                  (C++ 内核 + Python/Java 绑定)                              │ │
│   │                                                                            │ │
│   │   功能:                                                                    │ │
│   │   ├── 肌骨模型仿真 (Musculoskeletal Simulation)                            │ │
│   │   ├── 逆运动学 (Inverse Kinematics) - 从标记点→关节角度                     │ │
│   │   ├── 逆动力学 (Inverse Dynamics) - 从运动→关节力矩                         │ │
│   │   ├── 静态优化 (Static Optimization) - 估算肌肉力量                         │ │
│   │   └── 计算肌肉控制 (CMC) - EMG 驱动仿真                                     │ │
│   │                                                                            │ │
│   │   许可证: Apache 2.0 (商业友好)                                             │ │
│   │   GitHub: github.com/opensim-org/opensim-core (3.4k stars)                 │ │
│   └───────────────────────────────────────────────────────────────────────────┘ │
│                                      │                                          │
│              ┌───────────────────────┼───────────────────────┐                  │
│              ▼                       ▼                       ▼                  │
│   ┌──────────────────┐    ┌──────────────────┐    ┌──────────────────┐         │
│   │    OpenCap       │    │   OpenSense      │    │   EMG 驱动模型    │         │
│   │  (视觉输入)       │    │   (IMU 输入)     │    │   (肌电输入)       │         │
│   ├──────────────────┤    ├──────────────────┤    ├──────────────────┤         │
│   │                   │    │                   │    │                   │         │
│   │ 手机视频          │    │ IMU 传感器       │    │ EMG 信号         │         │
│   │     ↓            │    │     ↓            │    │     ↓            │         │
│   │ MediaPipe/SOTA   │    │ 方向估算         │    │ 肌肉激活曲线     │         │
│   │     ↓            │    │     ↓            │    │     ↓            │         │
│   │ OpenSim 格式     │    │ 关节角度         │    │ 驱动肌骨模型     │         │
│   │     ↓            │    │     ↓            │    │     ↓            │         │
│   │ 生物力学分析     │    │ 运动学分析       │    │ 肌肉力量估算     │         │
│   │                   │    │                   │    │                   │         │
│   │ 论文验证:         │    │ 论文验证:         │    │ 应用场景:         │         │
│   │ 平均误差 3cm     │    │ 膝关节误差 <4°   │    │ 康复、运动表现   │         │
│   └──────────────────┘    └──────────────────┘    └──────────────────┘         │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 与 Movement Chain AI 的整合机会

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    OpenSim × Movement Chain AI 整合矩阵                           │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   Movement Chain 模态        OpenSim 工具           整合价值                      │
│   ═══════════════════════════════════════════════════════════════════════════   │
│                                                                                  │
│   Vision (摄像头)      ←→    OpenCap                                             │
│   ├── MediaPipe 33点                                                             │
│   └── 整合方式: 用 OpenCap 验证 MediaPipe 精度                                    │
│       • OpenCap 论文: 平均误差 3cm                                               │
│       • 可作为 Ground Truth 评估 MediaPipe                                        │
│       • Phase 3: 可直接使用 OpenCap 管道                                          │
│                                                                                  │
│   IMU (手腕传感器)     ←→    OpenSense                                           │
│   ├── LSM6DSV16X 6轴                                                             │
│   └── 整合方式: 用 OpenSense 处理 IMU 数据                                        │
│       • 已有 ST MEMS Studio 整合插件                                              │
│       • 可将 IMU 方向 → 关节角度                                                  │
│       • 论文: 膝关节误差 <4°                                                      │
│                                                                                  │
│   EMG (肌电传感)       ←→    CMC/EMG-Informed                                    │
│   ├── 2-4通道肌电                                                                │
│   └── 整合方式: EMG 驱动 OpenSim 肌骨模型                                         │
│       • 用实测 EMG 约束肌肉激活估算                                               │
│       • 获得"真实"肌肉力量数据                                                   │
│       • 核心差异化: 竞品无法复制！                                                │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### OpenCap: 手机视频 → 生物力学分析

OpenCap 是斯坦福生物力学实验室的最新成果，可将普通手机视频转换为 OpenSim 兼容的运动数据。

**技术流程:**

```text
手机视频 (2台同步)
    ↓
LSTM 深度学习 (优于 MediaPipe)
    ↓
3D 关键点重建
    ↓
OpenSim 骨架缩放 (根据用户身高体重)
    ↓
OpenSim .mot 运动学文件
    ↓
逆动力学分析 → 关节力矩
    ↓
静态优化 → 肌肉力量估算
```

**论文验证 (2023):**

| 指标 | OpenCap 结果 | 对比 MediaPipe |
|-----|-------------|---------------|
| 平均位置误差 | 3 cm | ~5-8 cm |
| 关节角度误差 | <5° | ~8-12° |
| 与 Marker-based 相关性 | r > 0.9 | r ~0.7-0.8 |

**GitHub 资源:**

- 主仓库: [github.com/stanfordnmbl/opencap-core](https://github.com/stanfordnmbl/opencap-core)
- 处理管道: [github.com/stanfordnmbl/opencap-processing](https://github.com/stanfordnmbl/opencap-processing)

### OpenSense: IMU → 运动学分析

OpenSense 是 OpenSim 的 IMU 处理工具，可直接从惯性传感器获取关节角度。

**核心能力:**

```python
# OpenSense Python API 示例
import opensim as osim

# 加载 IMU 数据和模型
imu_data = osim.IMUDataReader('imu_data.sto')
model = osim.Model('scaled_model.osim')

# 运行逆运动学
imu_ik = osim.IMUInverseKinematicsTool()
imu_ik.setModel(model)
imu_ik.setIMUDataSource(imu_data)
imu_ik.run()

# 输出: 所有关节角度的时间序列
```

**与 Movement Chain IMU 的兼容性:**

| 项目 | LSM6DSV16X (我们的选择) | OpenSense 要求 |
|-----|------------------------|---------------|
| 轴数 | 6轴 (加速度+陀螺仪) | 9轴最佳, 6轴可用 |
| 采样率 | 100-200 Hz | 支持 |
| 数据格式 | 自定义 BLE | 需转换为 .sto |
| 校准 | 需要静态校准姿势 | N-Pose 或 T-Pose |

### EMG 驱动肌骨仿真

OpenSim 的 EMG-Assisted/Informed 方法可用实测肌电数据约束肌肉激活估算，这是 Movement Chain AI 的**核心差异化机会**。

**技术流程:**

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                     EMG-Informed OpenSim 仿真流程                                 │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   输入                    处理                         输出                       │
│   ─────                   ────                         ────                       │
│                                                                                  │
│   1. 运动学数据      →    逆动力学        →    关节力矩需求                        │
│      (OpenCap/IMU)                              τ = I·α + 重力                   │
│                                                                                  │
│   2. EMG 信号        →    归一化          →    肌肉激活曲线                        │
│      (NeuroKit2)          (MVC 标准化)         a(t) ∈ [0, 1]                      │
│                                                                                  │
│   3. 肌骨模型        →    肌肉优化        →    个体肌肉力量                        │
│      (.osim)              约束:                 F_muscle(t)                       │
│                           EMG 匹配                                               │
│                           力矩平衡                                               │
│                           最小化代价                                              │
│                                                                                  │
│   💡 关键洞察:                                                                   │
│   ├── 纯数学优化会"发明"肌肉激活模式，可能不符合真实                              │
│   ├── EMG 约束确保估算反映真实肌肉使用                                            │
│   └── 这是高尔夫挥杆分析的"黄金标准"                                             │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 高尔夫挥杆 OpenSim 研究

已有研究使用 OpenSim 分析高尔夫挥杆，我们可以借鉴：

| 研究 | 方法 | 关键发现 | 对我们的价值 |
|-----|-----|---------|------------|
| Evans et al. | 光学动捕 + OpenSim | 腹斜肌在下杆初期最先激活 | EMG 位置选择依据 |
| Cole & Grimshaw | EMG + 逆动力学 | 核心力矩峰值出现在击球前 50ms | 时序规则验证 |
| OpenCap Golf | 手机视频 + OpenSim | 下杆髋部旋转速度与距离正相关 | 可复现的开源方法 |

### 整合路线图

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                    OpenSim 整合分阶段计划                                         │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   Phase 1: 验证与对比 (MVP 并行)                                                 │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 用 OpenCap 收集 10-20 个挥杆样本                                       │   │
│   │ • 对比 MediaPipe vs OpenCap 精度差异                                     │   │
│   │ • 建立 Ground Truth 数据集                                               │   │
│   │ • 不整合到产品，仅用于评估                                                │   │
│   │                                                                          │   │
│   │ 工作量: ~2周 (熟悉工具 + 数据收集)                                        │   │
│   │ 依赖: 2台手机、三脚架、OpenCap 账户                                       │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                      ↓                                          │
│   Phase 2: IMU 整合 (Phase 2 产品)                                              │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 实现 LSM6DSV16X → OpenSense 数据转换器                                 │   │
│   │ • 用 OpenSim 验证我们的关节角度估算                                       │   │
│   │ • 探索 OpenSense 是否能替代/增强我们的 IMU 处理                           │   │
│   │                                                                          │   │
│   │ 工作量: ~3-4周                                                           │   │
│   │ 依赖: OpenSim Python API、数据格式转换脚本                                │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                      ↓                                          │
│   Phase 3: EMG + 生物力学分析 (Phase 3 产品)                                    │
│   ┌─────────────────────────────────────────────────────────────────────────┐   │
│   │ • 建立 EMG-Informed OpenSim 仿真管道                                     │   │
│   │ • 提供"肌肉力量估算"作为高级分析功能                                      │   │
│   │ • 训练高尔夫专用 OpenSim 模型 (肌骨几何优化)                              │   │
│   │ • 营销: "运动科学实验室级分析，只需手机和传感器"                           │   │
│   │                                                                          │   │
│   │ 工作量: ~2-3个月                                                         │   │
│   │ 依赖: 生物力学领域知识、EMG 数据标准化流程                                 │   │
│   └─────────────────────────────────────────────────────────────────────────┘   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### OpenSim GitHub 资源

| 仓库 | 星数 | 描述 | 使用场景 |
|-----|-----|------|---------|
| [opensim-core](https://github.com/opensim-org/opensim-core) | 3.4k | 核心仿真引擎 | Python API 集成 |
| [opencap-core](https://github.com/stanfordnmbl/opencap-core) | 200+ | 手机视频处理 | 验证 MediaPipe |
| [opencap-processing](https://github.com/stanfordnmbl/opencap-processing) | 100+ | 后处理管道 | 数据分析脚本 |
| OpenSense | 内置 | IMU 处理工具 (OpenSim 核心组件) | LSM6DSV16X 整合 |

### 成本与可行性评估

| 因素 | 评估 | 备注 |
|-----|-----|------|
| **许可证** | ✅ Apache 2.0 | 商业友好，无版权问题 |
| **学习曲线** | ⚠️ 中等 | 需要生物力学基础知识 |
| **计算需求** | ⚠️ 中等 | 仿真需要几秒到几分钟/次 |
| **精度提升** | ✅ 显著 | 从 ~70% → 90%+ 分析准确度 |
| **差异化价值** | ✅ 极高 | "科研级分析"营销卖点 |
| **MVP 必需** | ❌ 否 | Phase 2-3 整合即可 |

---

## 关键研究资源

### 姿态估计

| 资源 | 描述 | 链接 |
|-----|------|------|
| ViTPose++ | SOTA 81.1 AP | [GitHub](https://github.com/ViTAE-Transformer/ViTPose) |
| MMPose | OpenMMLab 工具箱 | [GitHub](https://github.com/open-mmlab/mmpose) |
| RTMPose | 实时优化 | [GitHub](https://github.com/open-mmlab/mmpose/tree/main/projects/rtmpose) |

### 高尔夫动作分析

| 资源 | 描述 | 链接 |
|-----|------|------|
| GolfDB | 挥杆数据集 + SwingNet | [GitHub](https://github.com/wmcnally/golfdb) |
| GolfMate | Explainable Embedding | [MDPI](https://www.mdpi.com/2076-3417/13/20/11227) |

### 多模态融合

| 资源 | 描述 | 链接 |
|-----|------|------|
| TransPose | 6 IMU 姿态估计 | [GitHub](https://github.com/Xinyu-Yi/TransPose) |
| sEMG-IMU 融合综述 | 上肢动作识别 | [ScienceDirect](https://www.sciencedirect.com/science/article/pii/S1566253525004956) |

---

## 总结

| 问题 | 答案 |
|-----|------|
| **端到端架构是什么？** | 数据采集 → 骨架提取 → 时间同步 → 特征提取 → 分析引擎 → 输出反馈 |
| **每层用什么技术？** | 见上文各层详细技术方案 |
| **MVP 用什么 AI？** | MediaPipe (姿态) + 规则引擎 (分析) + OpenCV (可视化) |
| **核心差异化在哪？** | EMG 肌肉时序分析 (规则8、9) — 竞品无法提供 |
| **需要从头训练 AI 吗？** | MVP 不需要，90% 有现成 SDK；Phase 2-3 训练分类器 |
| **AI 成本多少？** | MVP 几乎免费；Phase 2 LLM 约 $0.01-0.03/次 |

---

**相关文档:**

- [多模态融合算法](fusion-algorithm.md) - 时间同步与融合策略
- [传感器数据格式](sensor-data-formats.md) - Vision/IMU/EMG 数据规范
- [规则引擎](rule-engine.md) - 挥杆分析实现
- [反馈系统](feedback-system.md) - Ghost 指导与 UI 设计
- [MVP 原型代码](../platform/mvp-prototype-code.md) - 可运行代码示例

---

**最后更新**: 2025年12月11日
